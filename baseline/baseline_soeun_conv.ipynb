{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "# **ğŸ“„ Document type classification baseline code**\n",
    "> ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰     \n",
    "> ì•„ë˜ baselineì—ì„œëŠ” ResNet ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬, ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì¼ ìƒì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "## Version Info\n",
    "- ëª¨ë¸ í•™ìŠµ ë°©ë²• : ViT\n",
    "- Augmentation + í•˜ì´í¼íŒŒë¼ë¯¸í„° + ê°€ì¤‘ì¹˜ + ìŠ¤ì¼€ì¤„ëŸ¬ + weight decay + TTA + í™€ë“œì•„ì›ƒ + ì˜¤í”„ë¼ì¸ ì¦ê°•\n",
    "\n",
    "## Contents\n",
    "- Prepare Environments\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•œ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤.\n",
    "* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21945,
     "status": "ok",
     "timestamp": 1700314517484,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "pUjnEto4gIZm",
    "outputId": "0999f10c-e1ff-428c-995b-481eec8a0b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸, Colabì„ ì´ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ íŒ¨ìŠ¤í•´ë„ ë©ë‹ˆë‹¤.\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive', force_remount=True)\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7640,
     "status": "ok",
     "timestamp": 1700314537985,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "5lFQ-gpjnN_m"
   },
   "outputs": [],
   "source": [
    "# êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œëœ ëŒ€íšŒ ë°ì´í„°ë¥¼ ì••ì¶• í•´ì œí•˜ê³  ë¡œì»¬ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "!tar -xvf drive/MyDrive/datasets_fin.tar > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /workspace/.venv/lib/python3.10/site-packages (1.0.22)\n",
      "Requirement already satisfied: torch in /workspace/.venv/lib/python3.10/site-packages (from timm) (2.9.0)\n",
      "Requirement already satisfied: torchvision in /workspace/.venv/lib/python3.10/site-packages (from timm) (0.24.0)\n",
      "Requirement already satisfied: pyyaml in /workspace/.venv/lib/python3.10/site-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /workspace/.venv/lib/python3.10/site-packages (from timm) (1.1.2)\n",
      "Requirement already satisfied: safetensors in /workspace/.venv/lib/python3.10/site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: filelock in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: shellingham in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: anyio in /workspace/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (4.11.0)\n",
      "Requirement already satisfied: certifi in /workspace/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /workspace/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.0.9)\n",
      "Requirement already satisfied: idna in /workspace/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /workspace/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /workspace/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspace/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm) (1.3.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.venv/lib/python3.10/site-packages (from jinja2->torch->timm) (3.0.3)\n",
      "Requirement already satisfied: numpy in /workspace/.venv/lib/python3.10/site-packages (from torchvision->timm) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspace/.venv/lib/python3.10/site-packages (from torchvision->timm) (12.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /workspace/.venv/lib/python3.10/site-packages (from typer-slim->huggingface_hub->timm) (8.3.0)\n",
      "Requirement already satisfied: augraphy in /workspace/.venv/lib/python3.10/site-packages (8.2.6)\n",
      "Requirement already satisfied: matplotlib>=3.4.3 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (3.10.7)\n",
      "Requirement already satisfied: numba>=0.57.0 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (0.62.1)\n",
      "Requirement already satisfied: numpy>=1.20.1 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (2.2.6)\n",
      "Requirement already satisfied: opencv-python>=4.5.1.48 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (4.12.0.88)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (12.0.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (2.32.5)\n",
      "Requirement already satisfied: scikit-image>=0.18.1 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (0.25.2)\n",
      "Requirement already satisfied: scikit-learn>=0.23.2 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (1.7.2)\n",
      "Requirement already satisfied: scipy>=1.6.3 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (1.15.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /workspace/.venv/lib/python3.10/site-packages (from numba>=0.57.0->augraphy) (0.45.1)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.4.3->augraphy) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (2025.10.5)\n",
      "Requirement already satisfied: networkx>=3.0 in /workspace/.venv/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (3.4.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /workspace/.venv/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /workspace/.venv/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (2025.5.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /workspace/.venv/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /workspace/.venv/lib/python3.10/site-packages (from scikit-learn>=0.23.2->augraphy) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /workspace/.venv/lib/python3.10/site-packages (from scikit-learn>=0.23.2->augraphy) (3.6.0)\n",
      "Requirement already satisfied: matplotlib in /workspace/.venv/lib/python3.10/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Hit:1 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Reading package lists... Done\n",
      "E: dpkg was interrupted, you must manually run 'dpkg --configure -a' to correct the problem. \n"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "!pip install timm\n",
    "!pip install augraphy\n",
    "!pip install matplotlib\n",
    "!apt-get update\n",
    "!apt-get install -y libgl1-mesa-glx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "os.makedirs(\"npy\", exist_ok=True)\n",
    "os.makedirs(\"submission\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = 'datasets_fin/'\n",
    "\n",
    "# model config\n",
    "model_name = 'convnext_base' # 'efficientnet_b1' #'resnet50' 'resnet34' # , ...\n",
    "\n",
    "# training config - ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì—¬ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŒ \n",
    "img_size = 384\n",
    "LR = 3e-5\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "num_workers = 2 # ì†ë„ í–¥ìƒì„ ìœ„í•´ ì¡°ì •\n",
    "N_SPLITS = 5  # 5-Fold êµì°¨ ê²€ì¦\n",
    "EARLY_STOPPING_PATIENCE = 10 # 5 ì—í¬í¬ ë™ì•ˆ ì ìˆ˜ í–¥ìƒ ì—†ìœ¼ë©´ ì¤‘ë‹¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… [V7 - ë²„ê·¸ í•´ê²°] ì°¨ì„¸ëŒ€ ì¦ê°• í•¨ìˆ˜(Augraphy, Extreme Crop, Mixup) ì •ì˜ ì‹œì‘...\n",
      "âœ… [V7] ì°¨ì„¸ëŒ€ ì¦ê°• í•¨ìˆ˜(Augraphy, Extreme Crop, Mixup) ì •ì˜ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# [âœ… V7 - ë²„ê·¸ ìˆ˜ì •] 'import *'ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  'aug' ë³„ëª…ìœ¼ë¡œ ì„í¬íŠ¸\n",
    "import augraphy as aug \n",
    "from augraphy import OneOf as AugraphyOneOf \n",
    "\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision import transforms # [âœ… V6]\n",
    "\n",
    "print(\"âœ… [V7 - ë²„ê·¸ í•´ê²°] ì°¨ì„¸ëŒ€ ì¦ê°• í•¨ìˆ˜(Augraphy, Extreme Crop, Mixup) ì •ì˜ ì‹œì‘...\")\n",
    "\n",
    "# [âœ… V6] 1. Custom Crop í•¨ìˆ˜ ì •ì˜\n",
    "class QuarterDivide(ImageOnlyTransform):\n",
    "    def __init__(self, always_apply=False, p=1):\n",
    "        super().__init__(always_apply=always_apply, p=p)\n",
    "    def apply(self, img, **params):\n",
    "        height, width, _ = img.shape\n",
    "        center_x, center_y = width // 2, height // 2\n",
    "        results = [\n",
    "            img[0:center_y, 0:center_x], img[0:center_y, center_x:width],\n",
    "            img[center_y:height, 0:center_x], img[center_y:height, center_x:width]\n",
    "        ]\n",
    "        return results[random.randint(0, 3)]\n",
    "\n",
    "class HalfDivide(ImageOnlyTransform):\n",
    "    def __init__(self, always_apply=False, p=1):\n",
    "        super().__init__(always_apply=always_apply, p=p)\n",
    "    def apply(self, img, **params):\n",
    "        height, width, _ = img.shape\n",
    "        center_y = height // 2\n",
    "        results = [img[0:center_y, :], img[center_y:height, :]]\n",
    "        return results[random.randint(0, 1)]\n",
    "\n",
    "# [âœ… V6] 2. Augraphy (ë¬¼ë¦¬ ë…¸ì´ì¦ˆ) íŒŒì´í”„ë¼ì¸\n",
    "def augraphy_transform():\n",
    "    # [âœ… V7 - ë²„ê·¸ ìˆ˜ì •] 'aug' ë³„ëª… ë° 'AugraphyOneOf' ë³„ëª… ì‚¬ìš©\n",
    "    return aug.AugraphyPipeline(\n",
    "        paper_phase = [AugraphyOneOf([aug.NoiseTexturize(p=0.5), aug.BrightnessTexturize(p=0.5)], p=0.6)],\n",
    "        post_phase = [AugraphyOneOf([aug.LightingGradient(p=0.25), aug.ShadowCast(p=0.25)], p=0.25)]\n",
    "    )\n",
    "\n",
    "# [âœ… V6] 3. Albumentations (ê¸°í•˜í•™/ì˜ë¦¼) íŒŒì´í”„ë¼ì¸\n",
    "# (A) 'ì¢…ì´ ì•„ë‹˜' (Non-Paper)ì„ ìœ„í•œ 'ê°€ë²¼ìš´' ì¦ê°•\n",
    "light_non_paper_augment = A.Compose([\n",
    "    A.Affine(rotate=(-20, 20), shear=(-10, 10), scale=(0.9, 1.1), p=0.8),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "    A.GaussNoise(var_limit=(10.0, 30.0), p=0.5),\n",
    "    A.HorizontalFlip(p=0.3),\n",
    "    A.Resize(height=img_size, width=img_size, always_apply=True, p=1.0), \n",
    "])\n",
    "# (B) 'ì¢…ì´' (Paper)ë¥¼ ìœ„í•œ 'ê°•ë ¥í•œ V6' ê¸°í•˜í•™(Geometric) ì¦ê°•\n",
    "def strong_paper_geometric_transform(img_h, img_w):\n",
    "    # [âœ… V7] ì—¬ê¸°ì„œëŠ” 'A.OneOf' (Albumentations)ë¥¼ ì‚¬ìš©\n",
    "    return A.Compose([\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=max(img_h, img_w), p=1),\n",
    "            A.PadIfNeeded(min_height=img_h, min_width=img_w, border_mode=0, value=(255, 255, 255), p=1),\n",
    "            A.OneOf([QuarterDivide(p=0.3), HalfDivide(p=0.3), A.RandomCrop(height=img_h//2, width=img_w//2, p=0.4)], p=0.6), \n",
    "        ], p=0.6), \n",
    "        A.OneOf([A.HorizontalFlip(p=0.3), A.VerticalFlip(p=0.3), A.Transpose(p=0.4)], p=0.6),\n",
    "        A.OneOf([A.RandomRotate90(p=0.2), A.ShiftScaleRotate(rotate_limit=(-60, 60), p=0.3)], p=0.6),\n",
    "        A.Resize(height=img_h, width=img_w, always_apply=True, p=1.0),\n",
    "    ])\n",
    "\n",
    "# [âœ… V6 - ë²„ê·¸ ìˆ˜ì •] PyTorch ìˆ˜ë™ Normalize ì •ì˜\n",
    "manual_norm = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# [âœ… V6] 4. Mixup í•¨ìˆ˜ ì •ì˜ (í•™ìŠµ ë£¨í”„ì—ì„œ ì‚¬ìš©)\n",
    "def mixup(image, targets, alpha=1.0):\n",
    "    indices = torch.randperm(image.size(0))\n",
    "    image_b = image[indices]\n",
    "    targets_b = targets[indices]\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    image_mixed = lam * image + (1 - lam) * image_b\n",
    "    targets_one_hot = torch.nn.functional.one_hot(targets, num_classes=17).float()\n",
    "    targets_b_one_hot = torch.nn.functional.one_hot(targets_b, num_classes=17).float()\n",
    "    targets_mixed = lam * targets_one_hot + (1 - lam) * targets_b_one_hot\n",
    "    return image_mixed, targets_mixed\n",
    "\n",
    "print(\"âœ… [V7] ì°¨ì„¸ëŒ€ ì¦ê°• í•¨ìˆ˜(Augraphy, Extreme Crop, Mixup) ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [âœ… V6 - ë²„ê·¸ ìˆ˜ì •] Mixupì´ ì ìš©ëœ 'train_one_epoch'\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"===========================================\")\n",
    "    print(loader)\n",
    "    pbar = tqdm(loader)\n",
    "    \n",
    "    for image, targets in pbar:\n",
    "        # imageëŠ” (B, C, H, W) 0-255 í…ì„œ\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # --- [âœ… V6 Mixup ë¡œì§] ---\n",
    "        if random.random() < 0.5: # 50% í™•ë¥ ë¡œ Mixup\n",
    "            image_mixed, targets_mixed = mixup(image, targets, alpha=1.0)\n",
    "            \n",
    "            # [âœ… V6 - ë²„ê·¸ ìˆ˜ì •] ìˆ˜ë™ Normalize (0-1 ìŠ¤ì¼€ì¼ë§ í›„)\n",
    "            image_to_train = manual_norm(image_mixed / 255.0)\n",
    "            targets_to_train = targets_mixed.to(device)\n",
    "        else: # 50% í™•ë¥ ë¡œ ì›ë³¸ í•™ìŠµ\n",
    "            # [âœ… V6 - ë²„ê·¸ ìˆ˜ì •] ìˆ˜ë™ Normalize (0-1 ìŠ¤ì¼€ì¼ë§ í›„)\n",
    "            image_to_train = manual_norm(image / 255.0)\n",
    "            targets_to_train = torch.nn.functional.one_hot(targets, num_classes=17).float().to(device)\n",
    "        # -----------------------------\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        preds = model(image_to_train)\n",
    "        \n",
    "        # [âœ… V6] Mixup ë¼ë²¨(float)ê³¼ ì˜ˆì¸¡(logit)ì˜ Loss ê³„ì‚°\n",
    "        loss = -torch.mean(torch.sum(targets_to_train * torch.log_softmax(preds, dim=1), dim=1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    ret = {\"train_loss\": train_loss, \"train_acc\": 0, \"train_f1\": 0}\n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ë°ì´í„°: 1570, í•™ìŠµìš©: 1256, ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œìš©: 314\n"
     ]
    }
   ],
   "source": [
    "# ì›ë³¸ CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "all_df = pd.read_csv(\"datasets_fin/train.csv\")\n",
    "\n",
    "# [âœ… í•µì‹¬] 1570ê°œë¥¼ 8:2 ë¹„ìœ¨ë¡œ 'í•™ìŠµìš©'ê³¼ 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œìš©'ìœ¼ë¡œ ë¶„ë¦¬\n",
    "# stratify=all_df['target'] : 17ê°œ í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ì„ì–´ì¤Œ (Macro F1 ë¬¸ì œ í•´ê²°!)\n",
    "train_df, holdout_df = train_test_split(\n",
    "    all_df, \n",
    "    test_size=0.2,    # 20%ë¥¼ ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ(holdout)ë¡œ ì‚¬ìš©\n",
    "    random_state=42,  # í•­ìƒ ë™ì¼í•˜ê²Œ ë¶„ë¦¬\n",
    "    stratify=all_df['target'] \n",
    ")\n",
    "\n",
    "# í•™ìŠµì€ 80% ë°ì´í„°ë¡œë§Œ ì§„í–‰ (1570 * 0.8 = ì•½ 1256ê°œ)\n",
    "df = train_df.reset_index(drop=True) \n",
    "\n",
    "print(f\"ì´ ë°ì´í„°: {len(all_df)}, í•™ìŠµìš©: {len(df)}, ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œìš©: {len(holdout_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation í•¨ìˆ˜\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad(): # ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™”\n",
    "        pbar = tqdm(loader, desc=\"Valid\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            pbar.set_description(f\"Valid Loss: {loss.item():.4f}\")\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro') # Macro F1\n",
    "\n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# [âœ… V6 - ìˆ˜ì •ë¨] 'ì°¨ì„¸ëŒ€ ì¦ê°•' ì¡°ê±´ë¶€ ImageDataset\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    # [âœ… ì‚¬ìš©ìë‹˜ ë¶„ë¥˜ ê¸°ì¤€] (ì´ì „ì— ì‚¬ìš©í•œ V5 ë¦¬ìŠ¤íŠ¸)\n",
    "    PAPER_TARGETS = {1, 3, 4, 6, 7, 11, 12, 14, 15, 0, 10, 13} # 'ì¢…ì´' ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "    def __init__(self, df, path, \n",
    "                 mode='train', # 'train', 'val', 'test' ëª¨ë“œ\n",
    "                 img_size=img_size, \n",
    "                 target_col='target'):\n",
    "        \n",
    "        self.df = df \n",
    "        self.path = path\n",
    "        self.target_col = target_col\n",
    "        self.mode = mode\n",
    "        self.img_size = img_size\n",
    "\n",
    "        # --- [V6] íŒŒì´í”„ë¼ì¸ì„ __init__ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±! ---\n",
    "        if mode == 'train':\n",
    "            self.augraphy_pipe = augraphy_transform()\n",
    "            self.strong_geometric_pipe = strong_paper_geometric_transform(img_size, img_size)\n",
    "            self.mild_pipe = light_non_paper_augment\n",
    "            # (NormalizeëŠ” Cell 8ì—ì„œ ìˆ˜ë™ ì²˜ë¦¬)\n",
    "        else:\n",
    "            self.val_pipe = val_transform # (Cell 8ì—ì„œ ì •ì˜ë¨)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.df.iloc[idx]['ID']\n",
    "        target = self.df.iloc[idx][self.target_col]\n",
    "        \n",
    "        img_path = os.path.join(self.path, name)\n",
    "        try:\n",
    "            image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {img_path}: {e}\")\n",
    "            return torch.randn(3, self.img_size, self.img_size), 0\n",
    "            \n",
    "        # --- [âœ… V6 í•µì‹¬ ë¡œì§] ---\n",
    "        if self.mode == 'train':\n",
    "            if target in self.PAPER_TARGETS:\n",
    "                image = self.augraphy_pipe(image=image)['image']\n",
    "                image = self.strong_geometric_pipe(image=image)['image']\n",
    "            else:\n",
    "                image = self.mild_pipe(image=image)['image']\n",
    "            \n",
    "            # [âœ… V6] 0-255 í…ì„œë¡œ ë³€í™˜ (NormalizeëŠ” Cell 8ì—ì„œ)\n",
    "            img = torch.from_numpy(image.transpose((2, 0, 1))).float() # (H, W, C) -> (C, H, W)\n",
    "                \n",
    "        else: # 'val' ë˜ëŠ” 'test' ëª¨ë“œ\n",
    "            img = self.val_pipe(image=image)['image'] # val_pipeëŠ” Normalize/ToTensorV2 í¬í•¨\n",
    "            \n",
    "        return img, target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•™ìŠµìš© ì›ë³¸ ë°ì´í„°(df) ë¡œë“œ ì¤‘... (ì´ 1256ê°œ)\n",
      "ê²€ì¦ìš© í™€ë“œì•„ì›ƒ(holdout_df) ë¡œë“œ ì¤‘... (ì´ 314ê°œ)\n",
      "--- 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' í•™ìŠµ ì‹œì‘ (V6 Augraphy + Mixup) ---\n",
      "í•™ìŠµ ë°ì´í„°: 1256ê°œ (ì˜¨ë¼ì¸ V6 ì¦ê°•)\n",
      "ê²€ì¦ ë°ì´í„°: 314ê°œ (ê¹¨ë—í•œ ì›ë³¸)\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:38<00:00,  4.07it/s]\n",
      "Valid Loss: 0.9130: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:06<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [45s] - Train F1: 0.0000, Valid F1 (Holdout): 0.7668, Valid Loss: 0.6489\n",
      "â­ï¸ Best F1 Score updated to 0.7668. Model saved!\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4854: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:29<00:00,  5.30it/s]\n",
      "Valid Loss: 0.7266: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [31s] - Train F1: 0.0000, Valid F1 (Holdout): 0.8471, Valid Loss: 0.4122\n",
      "â­ï¸ Best F1 Score updated to 0.8471. Model saved!\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:33<00:00,  4.74it/s]\n",
      "Valid Loss: 0.9173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [34s] - Train F1: 0.0000, Valid F1 (Holdout): 0.8523, Valid Loss: 0.3282\n",
      "â­ï¸ Best F1 Score updated to 0.8523. Model saved!\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3755: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.76it/s]\n",
      "Valid Loss: 0.4596: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [34s] - Train F1: 0.0000, Valid F1 (Holdout): 0.8799, Valid Loss: 0.2922\n",
      "â­ï¸ Best F1 Score updated to 0.8799. Model saved!\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4460: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.84it/s]\n",
      "Valid Loss: 0.4344: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.8740, Valid Loss: 0.2492\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4725: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.90it/s]\n",
      "Valid Loss: 0.6200: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.8735, Valid Loss: 0.3006\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4931: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:31<00:00,  4.96it/s]\n",
      "Valid Loss: 0.2129: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9016, Valid Loss: 0.2242\n",
      "â­ï¸ Best F1 Score updated to 0.9016. Model saved!\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:31<00:00,  4.96it/s]\n",
      "Valid Loss: 0.2424: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9169, Valid Loss: 0.2132\n",
      "â­ï¸ Best F1 Score updated to 0.9169. Model saved!\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:30<00:00,  5.18it/s]\n",
      "Valid Loss: 0.4205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 [31s] - Train F1: 0.0000, Valid F1 (Holdout): 0.8990, Valid Loss: 0.2237\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3048: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.86it/s]\n",
      "Valid Loss: 0.0809: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9240, Valid Loss: 0.1996\n",
      "â­ï¸ Best F1 Score updated to 0.9240. Model saved!\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:31<00:00,  5.06it/s]\n",
      "Valid Loss: 0.1494: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 [32s] - Train F1: 0.0000, Valid F1 (Holdout): 0.8749, Valid Loss: 0.2712\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3339: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.84it/s]\n",
      "Valid Loss: 0.4569: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.8961, Valid Loss: 0.2210\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7217: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:30<00:00,  5.07it/s]\n",
      "Valid Loss: 0.0536: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 [32s] - Train F1: 0.0000, Valid F1 (Holdout): 0.8946, Valid Loss: 0.2457\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1577: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:31<00:00,  4.97it/s]\n",
      "Valid Loss: 0.2346: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9147, Valid Loss: 0.1762\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0717: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.80it/s]\n",
      "Valid Loss: 0.2473: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 [34s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9302, Valid Loss: 0.1760\n",
      "â­ï¸ Best F1 Score updated to 0.9302. Model saved!\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5386: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.84it/s]\n",
      "Valid Loss: 0.2563: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9210, Valid Loss: 0.1830\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1580: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:33<00:00,  4.72it/s]\n",
      "Valid Loss: 0.2300: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 [34s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9034, Valid Loss: 0.2098\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4559: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:30<00:00,  5.19it/s]\n",
      "Valid Loss: 0.5013: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 [31s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9076, Valid Loss: 0.2195\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1889:   1%|          | 1/157 [00:00<00:55,  2.80it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.0635: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.85it/s]\n",
      "Valid Loss: 0.2260: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9125, Valid Loss: 0.1868\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "Exception ignored in:     if w.is_alive():<function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "Traceback (most recent call last):\n",
      "      File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'    \n",
      "self._shutdown_workers()AssertionError\n",
      ":   File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "can only test a child process    if w.is_alive():\n",
      "\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    Exception ignored in: assert self._parent_pid == os.getpid(), 'can only test a child process'<function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "AssertionError\n",
      ": Traceback (most recent call last):\n",
      "can only test a child process  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "\n",
      "    Exception ignored in: self._shutdown_workers()\n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "\n",
      "Traceback (most recent call last):\n",
      "      File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "if w.is_alive():\n",
      "      File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "self._shutdown_workers()\n",
      "      File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "    AssertionErrorif w.is_alive():: can only test a child process\n",
      "\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.4029: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.83it/s]\n",
      "Valid Loss: 0.1443: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 [34s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9192, Valid Loss: 0.1831\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0983:   1%|          | 1/157 [00:00<01:03,  2.47it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.0530: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:29<00:00,  5.29it/s]\n",
      "Valid Loss: 0.1790: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 [31s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9181, Valid Loss: 0.2182\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.4879:   4%|â–         | 6/157 [00:01<00:22,  6.76it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.6316: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:29<00:00,  5.35it/s]\n",
      "Valid Loss: 0.1263: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 [30s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9166, Valid Loss: 0.1827\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.0304: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:34<00:00,  4.49it/s]\n",
      "Valid Loss: 0.0244: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 [36s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9551, Valid Loss: 0.1535\n",
      "â­ï¸ Best F1 Score updated to 0.9551. Model saved!\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0229:   1%|          | 1/157 [00:00<00:58,  2.66it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.3007: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:33<00:00,  4.74it/s]\n",
      "Valid Loss: 0.3599: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 [34s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9114, Valid Loss: 0.2257\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.4205: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:33<00:00,  4.71it/s]\n",
      "Valid Loss: 0.2400: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 [34s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9498, Valid Loss: 0.1498\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.7729: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:32<00:00,  4.78it/s]\n",
      "Valid Loss: 0.3630: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 [34s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9200, Valid Loss: 0.1973\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4196:   1%|          | 1/157 [00:00<01:02,  2.50it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.2560:   2%|â–         | 3/157 [00:01<00:56,  2.71it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "self._shutdown_workers()  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    \n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.5107: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:34<00:00,  4.51it/s]\n",
      "Valid Loss: 0.0976: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 [36s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9370, Valid Loss: 0.1681\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.1421: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:31<00:00,  4.91it/s]\n",
      "Valid Loss: 0.0274: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9484, Valid Loss: 0.1623\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/157 [00:00<?, ?it/s]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>Exception ignored in: \n",
      "<function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>Traceback (most recent call last):\n",
      "\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "Traceback (most recent call last):\n",
      "      File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "self._shutdown_workers()\n",
      "      File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "self._shutdown_workers()    \n",
      "if w.is_alive():  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "        if w.is_alive():assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "AssertionError    : assert self._parent_pid == os.getpid(), 'can only test a child process'can only test a child process\n",
      "\n",
      "AssertionError: Exception ignored in: can only test a child process<function _MultiProcessingDataLoaderIter.__del__ at 0x7f73f95efc70>\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1654, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/workspace/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1637, in _shutdown_workers\n",
      "    if w.is_alive():\n",
      "  File \"/opt/conda/lib/python3.10/multiprocessing/process.py\", line 160, in is_alive\n",
      "    assert self._parent_pid == os.getpid(), 'can only test a child process'\n",
      "AssertionError: can only test a child process\n",
      "Loss: 0.2695: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:35<00:00,  4.48it/s]\n",
      "Valid Loss: 0.1481: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 [36s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9287, Valid Loss: 0.2222\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0039: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:34<00:00,  4.57it/s]\n",
      "Valid Loss: 0.1570: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 [35s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9254, Valid Loss: 0.1842\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0369: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:31<00:00,  4.96it/s]\n",
      "Valid Loss: 0.0307: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 [33s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9420, Valid Loss: 0.1545\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6395: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:35<00:00,  4.46it/s]\n",
      "Valid Loss: 0.4847: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 [36s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9138, Valid Loss: 0.2184\n",
      "===========================================\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x7f73645075b0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9719: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 157/157 [00:33<00:00,  4.66it/s]\n",
      "Valid Loss: 0.4879: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 [35s] - Train F1: 0.0000, Valid F1 (Holdout): 0.9090, Valid Loss: 0.2591\n",
      "Early stopping at epoch 33 as F1 score did not improve for 10 epochs.\n",
      "--- V6 í•™ìŠµ ì™„ë£Œ ---\n",
      "ìµœì¢… 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' F1 ì ìˆ˜: 0.9551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# [âœ… V6 - ìˆ˜ì •ë¨] ImageDataset ìƒì„± (ì˜¨ë¼ì¸ ë°©ì‹)\n",
    "\n",
    "# 1. í•™ìŠµ ë°ì´í„° = 1256ê°œ ì›ë³¸ (df)\n",
    "# (V6ëŠ” 'ì˜¨ë¼ì¸' ì¦ê°•ì´ë¯€ë¡œ, 6280ê°œê°€ ì•„ë‹Œ 1256ê°œ ì›ë³¸(df)ì„ ì‚¬ìš©!)\n",
    "print(f\"í•™ìŠµìš© ì›ë³¸ ë°ì´í„°(df) ë¡œë“œ ì¤‘... (ì´ {len(df)}ê°œ)\")\n",
    "trn_dataset = ImageDataset(\n",
    "    df,                       # [âœ… V6] aug_df -> df (1256ê°œ)\n",
    "    \"datasets_fin/train/\",    # [âœ… V6] train_aug -> train (ì›ë³¸ í´ë”)\n",
    "    mode='train',             # [âœ… V6] 'train' ëª¨ë“œ\n",
    "    img_size=img_size,        # [âœ… V6] img_size ì „ë‹¬\n",
    "    target_col='target'\n",
    ")\n",
    "\n",
    "# 2. ê²€ì¦ ë°ì´í„° = 314ê°œ ê¹¨ë—í•œ í™€ë“œì•„ì›ƒ (holdout_df)\n",
    "print(f\"ê²€ì¦ìš© í™€ë“œì•„ì›ƒ(holdout_df) ë¡œë“œ ì¤‘... (ì´ {len(holdout_df)}ê°œ)\")\n",
    "val_dataset = ImageDataset(\n",
    "    holdout_df,               \n",
    "    \"datasets_fin/train/\",    \n",
    "    mode='val',               # [âœ… V6] 'val' ëª¨ë“œ\n",
    "    img_size=img_size,        # [âœ… V6] img_size ì „ë‹¬\n",
    "    target_col='target'\n",
    ")\n",
    "\n",
    "# DataLoader ì •ì˜\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "\n",
    "# [âœ… V6] Loss í•¨ìˆ˜ ìˆ˜ì • (ê²€ì¦ìš©)\n",
    "loss_fn = nn.CrossEntropyLoss() # (Mixupì€ Cell 8ì—ì„œ ìˆ˜ë™ ê³„ì‚°)\n",
    "\n",
    "# [âœ… V6] Optimizer ìˆ˜ì • (ConvNeXt/ViT/Swinì€ AdamW ì¶”ì²œ)\n",
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(model.parameters(), \n",
    "                  lr=LR, # (LR=3e-5 (ConvNeXt/ViT) ë˜ëŠ” 1e-4 (B4))\n",
    "                  weight_decay=1e-2 # (AdamWëŠ” 1e-2 ë˜ëŠ” 1e-4)\n",
    "                 )\n",
    "# (ë§Œì•½ Adamì„ ê³ ìˆ˜í•œë‹¤ë©´ optimizer = Adam(model.parameters(), lr=LR, weight_decay=1e-4))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "# Early Stoppingì„ ìœ„í•œ ë³€ìˆ˜\n",
    "best_val_f1 = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"--- 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' í•™ìŠµ ì‹œì‘ (V6 Augraphy + Mixup) ---\")\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {len(trn_dataset)}ê°œ (ì˜¨ë¼ì¸ V6 ì¦ê°•)\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ (ê¹¨ë—í•œ ì›ë³¸)\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    # [âœ… V6] Cell 8ì—ì„œ ì •ì˜ëœ V6 í•™ìŠµ ë£¨í”„ í˜¸ì¶œ\n",
    "    train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)\n",
    "    \n",
    "    val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} [{elapsed:.0f}s] - \"\n",
    "          f\"Train F1: {train_ret['train_f1']:.4f}, \" # (V6ëŠ” 0ìœ¼ë¡œ í‘œì‹œë¨)\n",
    "          f\"Valid F1 (Holdout): {val_ret['val_f1']:.4f}, \" # <- ì´ê²Œ ì§„ì§œ ì ìˆ˜\n",
    "          f\"Valid Loss: {val_ret['val_loss']:.4f}\")\n",
    "\n",
    "    # Early Stopping ë° ëª¨ë¸ ì €ì¥ ë¡œì§\n",
    "    if val_ret['val_f1'] > best_val_f1:\n",
    "        best_val_f1 = val_ret['val_f1']\n",
    "        torch.save(model.state_dict(), f\"model/best_conv_model_V6.pth\") \n",
    "        print(f\"â­ï¸ Best F1 Score updated to {best_val_f1:.4f}. Model saved!\")\n",
    "        patience_counter = 0 \n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch+1} as F1 score did not improve for {EARLY_STOPPING_PATIENCE} epochs.\")\n",
    "        break\n",
    "\n",
    "print(f\"--- V6 í•™ìŠµ ì™„ë£Œ ---\")\n",
    "print(f\"ìµœì¢… 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' F1 ì ìˆ˜: {best_val_f1:.4f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ì ìˆ˜ ê³„ì‚° ì‹œì‘ ---\n",
      "í™€ë“œì•„ì›ƒ ë°ì´í„°(holdout_df) ë¡œë“œ ì¤‘... (ì´ 314ê°œ)\n",
      "ëª¨ë¸ model/best_conv_model_V6.pth ë¡œë“œ ì™„ë£Œ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA ì¶”ë¡  ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ìµœì¢… ì ìˆ˜ ---\n",
      "âœ… TTA ì ìš© Macro F1: 0.9597\n",
      "   (TTA ì ìš© Accuracy: 0.9618)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ì ìˆ˜ ê³„ì‚° ì‹œì‘ ---\n",
    "print(\"--- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ì ìˆ˜ ê³„ì‚° ì‹œì‘ ---\")\n",
    "\n",
    "# (ì£¼ì˜: Cell 54ì—ì„œ ìƒì„±ëœ 'holdout_df' ë³€ìˆ˜ê°€ ì‚´ì•„ìˆì–´ì•¼ í•©ë‹ˆë‹¤)\n",
    "if 'holdout_df' not in globals():\n",
    "    print(\"ì˜¤ë¥˜: 'holdout_df'ê°€ ì—†ìŠµë‹ˆë‹¤. Load Data ì„¹í„°ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"í™€ë“œì•„ì›ƒ ë°ì´í„°(holdout_df) ë¡œë“œ ì¤‘... (ì´ {len(holdout_df)}ê°œ)\")\n",
    "\n",
    "    # 1. TTAìš© ë°ì´í„°ë¡œë” ìƒì„±\n",
    "    # [âœ… í•µì‹¬] 'transform=tst_transform'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤!\n",
    "    holdout_tta_dataset = ImageDataset(\n",
    "        holdout_df,               \n",
    "        \"datasets_fin/train/\",    \n",
    "        mode='val',               # [âœ… V6] 'val' ëª¨ë“œ\n",
    "        img_size=img_size,        # [âœ… V6] img_size ì „ë‹¬\n",
    "        target_col='target'\n",
    "    )\n",
    "\n",
    "    holdout_tta_loader = DataLoader(\n",
    "        holdout_tta_dataset,\n",
    "        batch_size=BATCH_SIZE * 2, # ì¶”ë¡ ì€ ë°°ì¹˜ 2ë°°ë¡œ\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 2. ì €ì¥ëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "    model_path = \"model/best_conv_model_V6.pth\" # í•™ìŠµì—ì„œ ì €ì¥ëœ ê²½ë¡œ\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    print(f\"ëª¨ë¸ {model_path} ë¡œë“œ ì™„ë£Œ.\")\n",
    "\n",
    "    # 3. TTA ì¶”ë¡  ì‹¤í–‰ (Inference ì„¹ì…˜ ì½”ë“œ ì¬í™œìš©)\n",
    "    tta_preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for image, _ in tqdm(holdout_tta_loader, desc=\"TTA ì¶”ë¡  ì¤‘\"):\n",
    "            image = image.to(device)\n",
    "            \n",
    "            # TTA 0: ì›ë³¸ ì˜ˆì¸¡\n",
    "            pred_orig = model(image)\n",
    "\n",
    "            # TTA 1: ì¢Œìš° ë°˜ì „\n",
    "            image_hflip = torch.flip(image, dims=[-1]) \n",
    "            pred_hflip = model(image_hflip)\n",
    "            \n",
    "            # TTA 2: 90ë„ íšŒì „\n",
    "            image_rot90 = torch.rot90(image, k=1, dims=[-2, -1])\n",
    "            pred_rot90 = model(image_rot90)\n",
    "\n",
    "            # 3ê°œ ì˜ˆì¸¡ì˜ í™•ë¥ (softmax)ì„ í‰ê· ëƒ„\n",
    "            avg_batch_pred = (pred_orig.softmax(dim=1) + \n",
    "                              pred_hflip.softmax(dim=1) + \n",
    "                              pred_rot90.softmax(dim=1)) / 3.0\n",
    "            \n",
    "            tta_preds_list.append(avg_batch_pred.cpu().numpy())\n",
    "    \n",
    "    # (314, 17) í¬ê¸°ì˜ ë°°ì—´ë¡œ í•©ì¹˜ê¸°\n",
    "    final_tta_preds_array = np.concatenate(tta_preds_list, axis=0)\n",
    "\n",
    "    # 4. TTA ì ìš© ì ìˆ˜ ê³„ì‚°\n",
    "    # ìµœì¢… ì˜ˆì¸¡ ë¼ë²¨ (ê°€ì¥ í™•ë¥  ë†’ì€ ê²ƒ)\n",
    "    final_tta_labels = np.argmax(final_tta_preds_array, axis=1)\n",
    "    \n",
    "    # ì‹¤ì œ ì •ë‹µ ë¼ë²¨\n",
    "    true_labels = holdout_df['target'].values\n",
    "    \n",
    "    # Macro F1 ìŠ¤ì½”ì–´ ê³„ì‚°\n",
    "    tta_f1_score = f1_score(true_labels, final_tta_labels, average='macro')\n",
    "    tta_acc_score = accuracy_score(true_labels, final_tta_labels)\n",
    "\n",
    "    print(\"\\n--- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ìµœì¢… ì ìˆ˜ ---\")\n",
    "    print(f\"âœ… TTA ì ìš© Macro F1: {tta_f1_score:.4f}\")\n",
    "    print(f\"   (TTA ì ìš© Accuracy: {tta_acc_score:.4f})\")\n",
    "    \n",
    "    # í™€ë“œì•„ì›ƒ ì˜ˆì¸¡ í™•ë¥  ì €ì¥\n",
    "    np.save(\"npy/conv_holdout_preds.npy\", final_tta_preds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ model/best_conv_model_V6.pth ë¡œë“œ ì™„ë£Œ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA ì¶”ë¡  ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:30<00:00,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt í‰ê·  í™•ë¥  ì €ì¥ ì™„ë£Œ!\n",
      "ì¶”ë¡  ì™„ë£Œ. ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tst_df = pd.read_csv(\"datasets_fin/sample_submission.csv\")\n",
    "# tst_dataset = ImageDataset(\n",
    "#     tst_df,\n",
    "#     \"datasets_fin/test/\",\n",
    "#     transform=tst_transform  # Test ì…‹ì—ëŠ” ì¦ê°•ì´ ì—†ëŠ” val_transform ì‚¬ìš©\n",
    "# )\n",
    "\n",
    "tst_dataset = ImageDataset(\n",
    "    tst_df,               \n",
    "    \"datasets_fin/test/\",    \n",
    "    mode='val',               # [âœ… V6] 'val' ëª¨ë“œ\n",
    ")\n",
    "\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# 2. ì €ì¥ëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "model_path = \"model/best_conv_model_V6.pth\" # í•™ìŠµì—ì„œ ì €ì¥ëœ ê²½ë¡œ\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "print(f\"ëª¨ë¸ {model_path} ë¡œë“œ ì™„ë£Œ.\")\n",
    "\n",
    "# 3. TTA ì¶”ë¡  ì‹¤í–‰ (Inference ì„¹ì…˜ ì½”ë“œ ì¬í™œìš©)\n",
    "tta_preds_list = []\n",
    "with torch.no_grad():\n",
    "    for image, _ in tqdm(tst_loader, desc=\"TTA ì¶”ë¡  ì¤‘\"):\n",
    "        image = image.to(device)\n",
    "        \n",
    "        # TTA 0: ì›ë³¸ ì˜ˆì¸¡\n",
    "        pred_orig = model(image)\n",
    "\n",
    "        # TTA 1: ì¢Œìš° ë°˜ì „\n",
    "        image_hflip = torch.flip(image, dims=[-1]) \n",
    "        pred_hflip = model(image_hflip)\n",
    "        \n",
    "        # TTA 2: 90ë„ íšŒì „\n",
    "        image_rot90 = torch.rot90(image, k=1, dims=[-2, -1])\n",
    "        pred_rot90 = model(image_rot90)\n",
    "\n",
    "        # 3ê°œ ì˜ˆì¸¡ì˜ í™•ë¥ (softmax)ì„ í‰ê· ëƒ„\n",
    "        avg_batch_pred = (pred_orig.softmax(dim=1) + \n",
    "                            pred_hflip.softmax(dim=1) + \n",
    "                            pred_rot90.softmax(dim=1)) / 3.0\n",
    "        \n",
    "        tta_preds_list.append(avg_batch_pred.cpu().numpy())\n",
    "\n",
    "# 4. ìµœì¢… ì˜ˆì¸¡ ë¼ë²¨ ìƒì„±\n",
    "final_tta_preds_array = np.concatenate(tta_preds_list, axis=0)\n",
    "\n",
    "np.save(\"npy/conv_final_preds.npy\", final_tta_preds_array) \n",
    "print(\"ConvNeXt í‰ê·  í™•ë¥  ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "final_tta_labels = np.argmax(final_tta_preds_array, axis=1)\n",
    "\n",
    "# 5. [âœ… ìˆ˜ì •ë¨] F1 ìŠ¤ì½”ì–´ ê³„ì‚° ë¶€ë¶„ ***ì™„ì „ ì‚­ì œ***\n",
    "# (ìš°ë¦¬ëŠ” 'ì§„ì§œ í…ŒìŠ¤íŠ¸ ë°ì´í„°'ì˜ ì •ë‹µì„ ëª¨ë¥´ë¯€ë¡œ ê³„ì‚° ë¶ˆê°€ëŠ¥)\n",
    "print(\"ì¶”ë¡  ì™„ë£Œ. ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "\n",
    "# 6. [âœ… ìˆ˜ì •ë¨] ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "pred_df = tst_df.copy()\n",
    "# [ì¤‘ìš”!] 'ê°€ì§œ ì •ë‹µ'(true_labels)ì´ ì•„ë‹Œ, 'ëª¨ë¸ì˜ ì˜ˆì¸¡'(final_tta_labels)ì„ ë„£ì–´ì•¼ í•¨\n",
    "pred_df['target'] = final_tta_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 12  5 ...  8  0 12]\n"
     ]
    }
   ],
   "source": [
    "print(final_tta_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (tst_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created!\n"
     ]
    }
   ],
   "source": [
    "pred_df.to_csv(\"submission/pred14.csv\", index=False)\n",
    "print(\"Submission file created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# submission.csv ë¡œë“œ\n",
    "submission_df = pd.read_csv(\"datasets_fin/submission.csv\")\n",
    "\n",
    "# minseo.csv ë¡œë“œ\n",
    "minseo_df = pd.read_csv(\"submission/pred14.csv\")\n",
    "\n",
    "# ë‘ dfì˜ target ë¶„í¬ ì‹œê°í™” bar plot ë¹„êµ, bar ìƒë‹¨ì— ê°¯ìˆ˜ í‘œì‹œ\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "submission_counts = submission_df['target'].value_counts().sort_index()\n",
    "bars = plt.bar(submission_counts.index, submission_counts.values, color='blue')\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 5, int(yval), ha='center', va='bottom')\n",
    "plt.subplot(1, 2, 2)\n",
    "minseo_counts = minseo_df['target'].value_counts().sort_index()\n",
    "bars = plt.bar(minseo_counts.index, minseo_counts.values, color='orange')\n",
    "for bar in bars:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval + 5, int(yval), ha='center', va='bottom')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
