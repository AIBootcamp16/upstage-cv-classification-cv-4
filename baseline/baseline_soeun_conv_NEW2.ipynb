{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "# **ğŸ“„ Document type classification baseline code**\n",
    "> ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰     \n",
    "> ì•„ë˜ baselineì—ì„œëŠ” ResNet ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬, ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì¼ ìƒì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "## Version Info\n",
    "- ëª¨ë¸ í•™ìŠµ ë°©ë²• : ViT\n",
    "- Augmentation + í•˜ì´í¼íŒŒë¼ë¯¸í„° + ê°€ì¤‘ì¹˜ + ìŠ¤ì¼€ì¤„ëŸ¬ + weight decay + TTA + í™€ë“œì•„ì›ƒ + ì˜¤í”„ë¼ì¸ ì¦ê°•\n",
    "\n",
    "## Contents\n",
    "- Prepare Environments\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•œ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤.\n",
    "* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21945,
     "status": "ok",
     "timestamp": 1700314517484,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "pUjnEto4gIZm",
    "outputId": "0999f10c-e1ff-428c-995b-481eec8a0b58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /gdrive\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸, Colabì„ ì´ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ íŒ¨ìŠ¤í•´ë„ ë©ë‹ˆë‹¤.\n",
    "from google.colab import drive\n",
    "drive.mount('/gdrive', force_remount=True)\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7640,
     "status": "ok",
     "timestamp": 1700314537985,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "5lFQ-gpjnN_m"
   },
   "outputs": [],
   "source": [
    "# êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œëœ ëŒ€íšŒ ë°ì´í„°ë¥¼ ì••ì¶• í•´ì œí•˜ê³  ë¡œì»¬ì— ì €ì¥í•©ë‹ˆë‹¤.\n",
    "!tar -xvf drive/MyDrive/datasets_fin.tar > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /opt/conda/lib/python3.10/site-packages (0.9.12)\n",
      "Requirement already satisfied: torch>=1.7 in /opt/conda/lib/python3.10/site-packages (from timm) (2.1.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from timm) (0.16.0)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm) (6.0)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm) (0.19.4)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm) (0.4.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (1.11.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7->timm) (2023.9.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (4.65.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm) (23.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (1.26.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->timm) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7->timm) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub->timm) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install augraphy\n",
    "!pip install matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# [âœ… V6 - êµì²´ë¨] Mixupì´ ì ìš©ëœ 'train_one_epoch'\n",
    "\n",
    "# (Cell 14ì—ì„œ ì •ì˜í•œ final_norm_pipeë¥¼ ì‚¬ìš©)\n",
    "norm_transform = final_norm_pipe \n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = [] # (Mixup ë¼ë²¨ì€ floatì´ë¯€ë¡œ, acc/f1 ê³„ì‚°ì´ ì–´ë ¤ì›€)\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # --- [âœ… V6 Mixup ë¡œì§] ---\n",
    "        # 1. 50% í™•ë¥ ë¡œ Mixup ì ìš©\n",
    "        if random.random() < 0.5:\n",
    "            # 2. Mixup ìˆ˜í–‰ (Cell 14ì— ì •ì˜ëœ í•¨ìˆ˜)\n",
    "            # (imageëŠ” 0-255 í…ì„œ, targetsëŠ” 1ì°¨ì› ë¼ë²¨)\n",
    "            image_mixed, targets_mixed = mixup(image, targets, alpha=1.0)\n",
    "            \n",
    "            # 3. [âœ… V6] Normalize/ToTensorV2ë¥¼ ì—¬ê¸°ì„œ ìˆ˜ë™ ì ìš©\n",
    "            # (Albumentationsì˜ ComposeëŠ” í…ì„œë¥¼ ëª» ë°›ìœ¼ë¯€ë¡œ, ìˆ˜ë™ ì ìš©)\n",
    "            image_mixed_norm = norm_transform(image=image_mixed.cpu().numpy().transpose(0, 2, 3, 1).astype(np.uint8))['image']\n",
    "            image_to_train = image_mixed_norm.to(device)\n",
    "            targets_to_train = targets_mixed.to(device) # (Mixupëœ float ë¼ë²¨)\n",
    "            \n",
    "        else:\n",
    "            # 4. Mixup ë¯¸ì ìš© (ì›ë³¸ í•™ìŠµ)\n",
    "            image_norm = norm_transform(image=image.cpu().numpy().transpose(0, 2, 3, 1).astype(np.uint8))['image']\n",
    "            image_to_train = image_norm.to(device)\n",
    "            # 5. [âœ…] Loss ê³„ì‚°ì„ ìœ„í•´ ë¼ë²¨ì„ ì›-í•«ìœ¼ë¡œ ë³€ê²½\n",
    "            targets_to_train = torch.nn.functional.one_hot(targets, num_classes=17).float().to(device)\n",
    "        # -----------------------------\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        \n",
    "        preds = model(image_to_train)\n",
    "        \n",
    "        # [âœ… V6] Mixup ë¼ë²¨(float)ê³¼ ì˜ˆì¸¡(logit)ì˜ Loss ê³„ì‚°\n",
    "        # (CrossEntropyLossëŠ” float ë¼ë²¨ì„ ëª» ë°›ìœ¼ë¯€ë¡œ, ìˆ˜ë™ ê³„ì‚°)\n",
    "        loss = -torch.mean(torch.sum(targets_to_train * torch.log_softmax(preds, dim=1), dim=1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # (Mixup ì¤‘ì—ëŠ” F1/Acc ê³„ì‚°ì´ ë¶€ì •í™•í•˜ë¯€ë¡œ, Lossë§Œ ì¶”ì )\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": 0, # (F1/Acc ê³„ì‚° ìƒëµ)\n",
    "        \"train_f1\": 0,  # (F1/Acc ê³„ì‚° ìƒëµ)\n",
    "    }\n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = 'datasets_fin/'\n",
    "\n",
    "# model config\n",
    "model_name = 'convnext_base' # 'efficientnet_b1' #'resnet50' 'resnet34' # , ...\n",
    "\n",
    "# training config - ì´ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì—¬ ì„±ëŠ¥ì„ ë†’ì¼ ìˆ˜ ìˆìŒ \n",
    "img_size = 224\n",
    "LR = 3e-5\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 8\n",
    "num_workers = 2 # ì†ë„ í–¥ìƒì„ ìœ„í•´ ì¡°ì •\n",
    "N_SPLITS = 5  # 5-Fold êµì°¨ ê²€ì¦\n",
    "EARLY_STOPPING_PATIENCE = 10 # 5 ì—í¬í¬ ë™ì•ˆ ì ìˆ˜ í–¥ìƒ ì—†ìœ¼ë©´ ì¤‘ë‹¨\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ ë°ì´í„°: 1570, K-Fold í•™ìŠµìš©: 1256, ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œìš©: 314\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ì›ë³¸ CSV ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "all_df = pd.read_csv(\"datasets_fin/train.csv\")\n",
    "\n",
    "# [âœ… í•µì‹¬] 1570ê°œë¥¼ 8:2 ë¹„ìœ¨ë¡œ 'í•™ìŠµìš©'ê³¼ 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œìš©'ìœ¼ë¡œ ë¶„ë¦¬\n",
    "# stratify=all_df['target'] : 17ê°œ í´ë˜ìŠ¤ ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ì„ì–´ì¤Œ (Macro F1 ë¬¸ì œ í•´ê²°!)\n",
    "train_df, holdout_df = train_test_split(\n",
    "    all_df, \n",
    "    test_size=0.2,    # 20%ë¥¼ ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ(holdout)ë¡œ ì‚¬ìš©\n",
    "    random_state=42,  # í•­ìƒ ë™ì¼í•˜ê²Œ ë¶„ë¦¬\n",
    "    stratify=all_df['target'] \n",
    ")\n",
    "\n",
    "# í•™ìŠµì€ 80% ë°ì´í„°ë¡œë§Œ ì§„í–‰ (1570 * 0.8 = ì•½ 1256ê°œ)\n",
    "df = train_df.reset_index(drop=True) \n",
    "\n",
    "print(f\"ì´ ë°ì´í„°: {len(all_df)}, K-Fold í•™ìŠµìš©: {len(df)}, ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œìš©: {len(holdout_df)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from augraphy import * # [âœ… V6] Augraphy ì„í¬íŠ¸\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# [âœ… V6] 1. Custom Crop í•¨ìˆ˜ ì •ì˜\n",
    "class QuarterDivide(ImageOnlyTransform):\n",
    "    def __init__(self, always_apply=False, p=1):\n",
    "        super().__init__(always_apply=always_apply, p=p)\n",
    "    def apply(self, img, **params):\n",
    "        height, width, _ = img.shape\n",
    "        center_x, center_y = width // 2, height // 2\n",
    "        results = [\n",
    "            img[0:center_y, 0:center_x], img[0:center_y, center_x:width],\n",
    "            img[center_y:height, 0:center_x], img[center_y:height, center_x:width]\n",
    "        ]\n",
    "        return results[random.randint(0, 3)]\n",
    "\n",
    "class HalfDivide(ImageOnlyTransform):\n",
    "    def __init__(self, always_apply=False, p=1):\n",
    "        super().__init__(always_apply=always_apply, p=p)\n",
    "    def apply(self, img, **params):\n",
    "        height, width, _ = img.shape\n",
    "        center_y = height // 2\n",
    "        results = [img[0:center_y, :], img[center_y:height, :]]\n",
    "        return results[random.randint(0, 1)]\n",
    "\n",
    "# [âœ… V6] 2. Augraphy (ë¬¼ë¦¬ ë…¸ì´ì¦ˆ) íŒŒì´í”„ë¼ì¸\n",
    "def augraphy_transform():\n",
    "    return AugraphyPipeline(\n",
    "        paper_phase = [\n",
    "            OneOf([\n",
    "                NoiseTexturize(sigma_range=(5, 15), p=0.5),\n",
    "                BrightnessTexturize(texturize_range=(0.8, 0.99), p=0.5),\n",
    "            ], p=0.6),\n",
    "        ],\n",
    "        post_phase = [\n",
    "            OneOf([\n",
    "                LightingGradient(direction=90, transparency=0.5, p=0.25),\n",
    "                ShadowCast(shadow_side=\"bottom\", shadow_blur_kernel_range=(101, 301), p=0.25)\n",
    "            ], p=0.25),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# [âœ… V6] 4. Mixup í•¨ìˆ˜ ì •ì˜ (í•™ìŠµ ë£¨í”„ì—ì„œ ì‚¬ìš©)\n",
    "def mixup(image, targets, alpha=1.0):\n",
    "    indices = torch.randperm(image.size(0))\n",
    "    image_b = image[indices]\n",
    "    targets_b = targets[indices]\n",
    "    \n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    \n",
    "    # Mixup ì´ë¯¸ì§€\n",
    "    image_mixed = lam * image + (1 - lam) * image_b\n",
    "    \n",
    "    # Mixup ë¼ë²¨ (ì›-í•« ì¸ì½”ë”© í›„ ì„ê¸°)\n",
    "    targets_one_hot = torch.nn.functional.one_hot(targets, num_classes=17).float()\n",
    "    targets_b_one_hot = torch.nn.functional.one_hot(targets_b, num_classes=17).float()\n",
    "    targets_mixed = lam * targets_one_hot + (1 - lam) * targets_b_one_hot\n",
    "    \n",
    "    return image_mixed, targets_mixed\n",
    "\n",
    "print(\"âœ… [V6] ì°¨ì„¸ëŒ€ ì¦ê°• í•¨ìˆ˜(Augraphy, Extreme Crop, Mixup) ì •ì˜ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation í•¨ìˆ˜\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    model.eval() # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    with torch.no_grad(): # ê¸°ìš¸ê¸° ê³„ì‚° ë¹„í™œì„±í™”\n",
    "        pbar = tqdm(loader, desc=\"Valid\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            pbar.set_description(f\"Valid Loss: {loss.item():.4f}\")\n",
    "\n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro') # Macro F1\n",
    "\n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# [âœ… V6 - ìˆ˜ì •ë¨] 'ì°¨ì„¸ëŒ€ ì¦ê°•' ì¡°ê±´ë¶€ ImageDataset\n",
    "class ImageDataset(Dataset):\n",
    "    \n",
    "    # [âœ… ì‚¬ìš©ìë‹˜ ë¶„ë¥˜ ê¸°ì¤€] (ì´ì „ì— ì‚¬ìš©í•œ V5 ë¦¬ìŠ¤íŠ¸)\n",
    "    PAPER_TARGETS = {1, 3, 4, 6, 7, 11, 12, 14, 15, 0, 10, 13} # 'ì¢…ì´' ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "    def __init__(self, df, path, \n",
    "                 mode='train', # 'train', 'val', 'test' ëª¨ë“œ\n",
    "                 img_size=224, \n",
    "                 target_col='target'):\n",
    "        \n",
    "        self.df = df \n",
    "        self.path = path\n",
    "        self.target_col = target_col\n",
    "        self.mode = mode\n",
    "\n",
    "        # --- [V6] íŒŒì´í”„ë¼ì¸ì„ __init__ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±! ---\n",
    "        if mode == 'train':\n",
    "            self.augraphy_pipe = augraphy_transform()\n",
    "            self.strong_geometric_pipe = strong_paper_geometric_transform(img_size, img_size)\n",
    "            self.mild_pipe = light_non_paper_augment\n",
    "            self.final_norm_pipe = final_norm_pipe # (Cell 14ì— ì •ì˜ë¨)\n",
    "        else:\n",
    "            self.val_pipe = val_transform # (Cell 14ì— ì •ì˜ë¨)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name = self.df.iloc[idx]['ID']\n",
    "        target = self.df.iloc[idx][self.target_col]\n",
    "        \n",
    "        img_path = os.path.join(self.path, name)\n",
    "        try:\n",
    "            image = np.array(Image.open(img_path).convert(\"RGB\"))\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening image {img_path}: {e}\")\n",
    "            return torch.randn(3, img_size, img_size), 0 \n",
    "            \n",
    "        # --- [âœ… V6 í•µì‹¬ ë¡œì§] ---\n",
    "        if self.mode == 'train':\n",
    "            if target in self.PAPER_TARGETS:\n",
    "                image = self.augraphy_pipe(image=image)['image']\n",
    "                image = self.strong_geometric_pipe(image=image)['image']\n",
    "            else:\n",
    "                image = self.mild_pipe(image=image)['image']\n",
    "            \n",
    "            # [âœ… ì¤‘ìš”] NormalizeëŠ” Mixupì„ ìœ„í•´ í•™ìŠµ ë£¨í”„ë¡œ ì´ë™!\n",
    "            # img = self.final_norm_pipe(image=image)['image']\n",
    "            # -> V6ëŠ” Normalize/ToTensorV2ë¥¼ Datasetì—ì„œ í•˜ì§€ ì•Šê³ ,\n",
    "            #    Mixup ì§ì „ì— ìˆ˜ë™ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n",
    "            \n",
    "            # [âœ… V6] Normalize/ToTensorV2 ëŒ€ì‹ , PIL Image -> Tensorë¡œë§Œ ë³€í™˜\n",
    "            # (Mixupì€ 0-255 ë²”ìœ„ì˜ í…ì„œë¥¼ ì„ì–´ì•¼ í•¨)\n",
    "            img = torch.from_numpy(image.transpose((2, 0, 1))).float() # (H, W, C) -> (C, H, W)\n",
    "                \n",
    "        else: # 'val' ë˜ëŠ” 'test' ëª¨ë“œ\n",
    "            img = self.val_pipe(image=image)['image'] # val_pipeëŠ” Normalize/ToTensorV2 í¬í•¨\n",
    "            \n",
    "        return img, target"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' í•™ìŠµ ì‹œì‘ ---\n",
      "í•™ìŠµ ë°ì´í„°: 6280ê°œ (ì¦ê°•ë¨)\n",
      "ê²€ì¦ ë°ì´í„°: 314ê°œ (ê¹¨ë—í•œ ì›ë³¸)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0466: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:23<00:00,  9.43it/s]\n",
      "Valid Loss: 0.2632: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:06<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 [90s] - Train F1: 0.7945, Valid F1 (Holdout): 0.8321, Valid Loss: 0.3092\n",
      "â­ï¸ Best F1 Score updated to 0.8321. Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1173: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:18<00:00,  9.95it/s]\n",
      "Valid Loss: 0.2177: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 [80s] - Train F1: 0.9127, Valid F1 (Holdout): 0.9241, Valid Loss: 0.2137\n",
      "â­ï¸ Best F1 Score updated to 0.9241. Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2171: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.92it/s]\n",
      "Valid Loss: 0.0941: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 [80s] - Train F1: 0.9397, Valid F1 (Holdout): 0.9327, Valid Loss: 0.1990\n",
      "â­ï¸ Best F1 Score updated to 0.9327. Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0190: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.93it/s]\n",
      "Valid Loss: 0.1817: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 [80s] - Train F1: 0.9603, Valid F1 (Holdout): 0.8899, Valid Loss: 0.3143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.2373: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.93it/s]\n",
      "Valid Loss: 0.0067: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 [80s] - Train F1: 0.9663, Valid F1 (Holdout): 0.9294, Valid Loss: 0.1778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3148: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0922: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 [80s] - Train F1: 0.9764, Valid F1 (Holdout): 0.9276, Valid Loss: 0.2133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0070: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 [80s] - Train F1: 0.9820, Valid F1 (Holdout): 0.9300, Valid Loss: 0.1957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0044: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.92it/s]\n",
      "Valid Loss: 0.0011: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 [80s] - Train F1: 0.9847, Valid F1 (Holdout): 0.9325, Valid Loss: 0.2503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0004: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.90it/s]\n",
      "Valid Loss: 0.0169: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 [80s] - Train F1: 0.9856, Valid F1 (Holdout): 0.9198, Valid Loss: 0.2359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0021: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 [80s] - Train F1: 0.9915, Valid F1 (Holdout): 0.9366, Valid Loss: 0.2204\n",
      "â­ï¸ Best F1 Score updated to 0.9366. Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0017: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0415: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 [80s] - Train F1: 0.9890, Valid F1 (Holdout): 0.9046, Valid Loss: 0.3449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0247: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.92it/s]\n",
      "Valid Loss: 0.0010: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 [80s] - Train F1: 0.9893, Valid F1 (Holdout): 0.9242, Valid Loss: 0.2529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0003: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.93it/s]\n",
      "Valid Loss: 0.0005: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 [80s] - Train F1: 0.9908, Valid F1 (Holdout): 0.9087, Valid Loss: 0.3581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0019: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0003: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 [80s] - Train F1: 0.9908, Valid F1 (Holdout): 0.9399, Valid Loss: 0.2481\n",
      "â­ï¸ Best F1 Score updated to 0.9399. Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0009: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.92it/s]\n",
      "Valid Loss: 0.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 [80s] - Train F1: 0.9879, Valid F1 (Holdout): 0.9166, Valid Loss: 0.3127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0055: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.90it/s]\n",
      "Valid Loss: 0.0004: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 [80s] - Train F1: 0.9922, Valid F1 (Holdout): 0.9321, Valid Loss: 0.2534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0005: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0003: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 [80s] - Train F1: 0.9941, Valid F1 (Holdout): 0.9312, Valid Loss: 0.3242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0007: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 [80s] - Train F1: 0.9912, Valid F1 (Holdout): 0.9153, Valid Loss: 0.2890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0040: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0040: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 39.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 [80s] - Train F1: 0.9924, Valid F1 (Holdout): 0.9270, Valid Loss: 0.3072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0194: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0159: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 [80s] - Train F1: 0.9928, Valid F1 (Holdout): 0.9351, Valid Loss: 0.2925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.1497: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.92it/s]\n",
      "Valid Loss: 0.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 [80s] - Train F1: 0.9908, Valid F1 (Holdout): 0.9411, Valid Loss: 0.2595\n",
      "â­ï¸ Best F1 Score updated to 0.9411. Model saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.92it/s]\n",
      "Valid Loss: 0.0022: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 [80s] - Train F1: 0.9935, Valid F1 (Holdout): 0.9246, Valid Loss: 0.2873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0009: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.92it/s]\n",
      "Valid Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 [80s] - Train F1: 0.9925, Valid F1 (Holdout): 0.9324, Valid Loss: 0.3190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.90it/s]\n",
      "Valid Loss: 0.0003: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 [80s] - Train F1: 0.9952, Valid F1 (Holdout): 0.9224, Valid Loss: 0.2786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0080: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 [80s] - Train F1: 0.9924, Valid F1 (Holdout): 0.9331, Valid Loss: 0.2999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.92it/s]\n",
      "Valid Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 [80s] - Train F1: 0.9950, Valid F1 (Holdout): 0.9234, Valid Loss: 0.2932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0019: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.90it/s]\n",
      "Valid Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 [80s] - Train F1: 0.9932, Valid F1 (Holdout): 0.9182, Valid Loss: 0.3409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.90it/s]\n",
      "Valid Loss: 0.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 37.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 [80s] - Train F1: 0.9929, Valid F1 (Holdout): 0.9391, Valid Loss: 0.2955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0019: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.92it/s]\n",
      "Valid Loss: 0.0018: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 [80s] - Train F1: 0.9946, Valid F1 (Holdout): 0.9225, Valid Loss: 0.3383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.93it/s]\n",
      "Valid Loss: 0.0001: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 [80s] - Train F1: 0.9954, Valid F1 (Holdout): 0.9293, Valid Loss: 0.3203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.0002: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 785/785 [01:19<00:00,  9.91it/s]\n",
      "Valid Loss: 0.0026: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 40/40 [00:01<00:00, 38.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 [80s] - Train F1: 0.9966, Valid F1 (Holdout): 0.9263, Valid Loss: 0.3374\n",
      "Early stopping at epoch 31 as F1 score did not improve for 10 epochs.\n",
      "--- í•™ìŠµ ì™„ë£Œ ---\n",
      "ìµœì¢… 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' F1 ì ìˆ˜: 0.9411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# [âœ… V6 - ìˆ˜ì •ë¨] ImageDataset ìƒì„±\n",
    "\n",
    "# 1. í•™ìŠµ ë°ì´í„° = 1256ê°œ ì›ë³¸ (df)\n",
    "# (V6ëŠ” 'ì˜¨ë¼ì¸' ì¦ê°•ì´ë¯€ë¡œ, 6280ê°œê°€ ì•„ë‹Œ 1256ê°œ ì›ë³¸(df)ì„ ì‚¬ìš©!)\n",
    "print(f\"í•™ìŠµìš© ì›ë³¸ ë°ì´í„°(df) ë¡œë“œ ì¤‘... (ì´ {len(df)}ê°œ)\")\n",
    "trn_dataset = ImageDataset(\n",
    "    df,                       # [âœ… V6] aug_df -> df (1256ê°œ)\n",
    "    \"datasets_fin/train/\",    # [âœ… V6] train_aug -> train (ì›ë³¸ í´ë”)\n",
    "    mode='train',             # [âœ… V6] 'train' ëª¨ë“œ\n",
    "    img_size=img_size,        # [âœ… V6] img_size ì „ë‹¬\n",
    "    target_col='target'\n",
    ")\n",
    "\n",
    "# 2. ê²€ì¦ ë°ì´í„° = 314ê°œ ê¹¨ë—í•œ í™€ë“œì•„ì›ƒ (holdout_df)\n",
    "print(f\"ê²€ì¦ìš© í™€ë“œì•„ì›ƒ(holdout_df) ë¡œë“œ ì¤‘... (ì´ {len(holdout_df)}ê°œ)\")\n",
    "val_dataset = ImageDataset(\n",
    "    holdout_df,               \n",
    "    \"datasets_fin/train/\",    \n",
    "    mode='val',               # [âœ… V6] 'val' ëª¨ë“œ\n",
    "    img_size=img_size,        # [âœ… V6] img_size ì „ë‹¬\n",
    "    target_col='target'\n",
    ")\n",
    "\n",
    "# DataLoader ì •ì˜\n",
    "trn_loader = DataLoader(\n",
    "    trn_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    drop_last=False\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# load model\n",
    "model = timm.create_model(\n",
    "    model_name,\n",
    "    pretrained=True,\n",
    "    num_classes=17\n",
    ").to(device)\n",
    "\n",
    "# [âœ… V6] Loss í•¨ìˆ˜ ìˆ˜ì • (Mixupì„ ìœ„í•´)\n",
    "# (Mixupì€ train_one_epochì—ì„œ Lossë¥¼ ìˆ˜ë™ ê³„ì‚°í•˜ë¯€ë¡œ,\n",
    "# loss_fnì€ 'ê²€ì¦ìš©(validation)'ìœ¼ë¡œë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.)\n",
    "loss_fn = nn.CrossEntropyLoss() # (ê°€ì¤‘ì¹˜ ê³„ì‚° ì‚­ì œ - ë‹¨ìˆœí™”)\n",
    "\n",
    "# ... (í•™ìŠµ ë£¨í”„ëŠ” ë™ì¼) ...\n",
    "# (í•™ìŠµ ë£¨í”„ì˜ Train F1/AccëŠ” 0ìœ¼ë¡œ ì¶œë ¥ë˜ì§€ë§Œ, \n",
    "#  Valid F1 (Holdout) ì ìˆ˜ê°€ 'ì§„ì§œ' ì ìˆ˜ì…ë‹ˆë‹¤.)\n",
    "\n",
    "# Optimizer, Scheduler\n",
    "optimizer = Adam(model.parameters(), lr=LR, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)\n",
    "\n",
    "# Early Stoppingì„ ìœ„í•œ ë³€ìˆ˜\n",
    "best_val_f1 = 0.0\n",
    "patience_counter = 0\n",
    "\n",
    "print(f\"--- 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' í•™ìŠµ ì‹œì‘ ---\")\n",
    "print(f\"í•™ìŠµ ë°ì´í„°: {len(trn_dataset)}ê°œ (ì¦ê°•ë¨)\")\n",
    "print(f\"ê²€ì¦ ë°ì´í„°: {len(val_dataset)}ê°œ (ê¹¨ë—í•œ ì›ë³¸)\")\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)\n",
    "    \n",
    "    # [í•µì‹¬] 314ê°œì˜ ê¹¨ë—í•œ í™€ë“œì•„ì›ƒ ì…‹ìœ¼ë¡œ ê²€ì¦\n",
    "    val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "    \n",
    "    train_ret['epoch'] = epoch\n",
    "    elapsed = time.time() - start_time\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} [{elapsed:.0f}s] - \"\n",
    "          f\"Train F1: {train_ret['train_f1']:.4f}, \"\n",
    "          f\"Valid F1 (Holdout): {val_ret['val_f1']:.4f}, \" # <- ì´ê²Œ ì§„ì§œ ì ìˆ˜\n",
    "          f\"Valid Loss: {val_ret['val_loss']:.4f}\")\n",
    "\n",
    "    # Early Stopping ë° ëª¨ë¸ ì €ì¥ ë¡œì§\n",
    "    if val_ret['val_f1'] > best_val_f1:\n",
    "        best_val_f1 = val_ret['val_f1']\n",
    "        \n",
    "        # [âœ… ìˆ˜ì •ë¨] ì €ì¥ ê²½ë¡œì—ì„œ {fold} ë³€ìˆ˜ ì œê±°\n",
    "        torch.save(model.state_dict(), f\"model/best_conv_model_old.pth\") \n",
    "        print(f\"â­ï¸ Best F1 Score updated to {best_val_f1:.4f}. Model saved!\")\n",
    "        patience_counter = 0 # ì´ˆê¸°í™”\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if patience_counter >= EARLY_STOPPING_PATIENCE:\n",
    "        print(f\"Early stopping at epoch {epoch+1} as F1 score did not improve for {EARLY_STOPPING_PATIENCE} epochs.\")\n",
    "        break\n",
    "\n",
    "print(f\"--- í•™ìŠµ ì™„ë£Œ ---\")\n",
    "print(f\"ìµœì¢… 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' F1 ì ìˆ˜: {best_val_f1:.4f}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug_df = pd.read_csv(\"datasets/aug_train.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ì ìˆ˜ ê³„ì‚° ì‹œì‘ ---\n",
      "í™€ë“œì•„ì›ƒ ë°ì´í„°(holdout_df) ë¡œë“œ ì¤‘... (ì´ 314ê°œ)\n",
      "ëª¨ë¸ model/best_conv_model.pth ë¡œë“œ ì™„ë£Œ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA ì¶”ë¡  ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [00:02<00:00,  7.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ìµœì¢… ì ìˆ˜ ---\n",
      "âœ… TTA ì ìš© Macro F1: 0.9792\n",
      "   (TTA ì ìš© Accuracy: 0.9809)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import timm\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ì ìˆ˜ ê³„ì‚° ì‹œì‘ ---\n",
    "print(\"--- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ì ìˆ˜ ê³„ì‚° ì‹œì‘ ---\")\n",
    "\n",
    "# (ì£¼ì˜: Cell 54ì—ì„œ ìƒì„±ëœ 'holdout_df' ë³€ìˆ˜ê°€ ì‚´ì•„ìˆì–´ì•¼ í•©ë‹ˆë‹¤)\n",
    "if 'holdout_df' not in globals():\n",
    "    print(\"ì˜¤ë¥˜: 'holdout_df'ê°€ ì—†ìŠµë‹ˆë‹¤. Load Data ì„¹í„°ë¥¼ ë‹¤ì‹œ ì‹¤í–‰í•´ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(f\"í™€ë“œì•„ì›ƒ ë°ì´í„°(holdout_df) ë¡œë“œ ì¤‘... (ì´ {len(holdout_df)}ê°œ)\")\n",
    "\n",
    "    # 1. TTAìš© ë°ì´í„°ë¡œë” ìƒì„±\n",
    "    # [âœ… í•µì‹¬] 'transform=tst_transform'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤!\n",
    "    holdout_tta_dataset = ImageDataset(\n",
    "        holdout_df,               \n",
    "        \"datasets_fin/train/\",    # ê¹¨ë—í•œ ì›ë³¸ ì´ë¯¸ì§€ê°€ ìˆëŠ” 'train' í´ë”\n",
    "        transform=tst_transform,  # TTAê°€ í¬í•¨ëœ 'tst_transform' ì‚¬ìš©\n",
    "        target_col='target'\n",
    "    )\n",
    "\n",
    "    holdout_tta_loader = DataLoader(\n",
    "        holdout_tta_dataset,\n",
    "        batch_size=BATCH_SIZE * 2, # ì¶”ë¡ ì€ ë°°ì¹˜ 2ë°°ë¡œ\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # 2. ì €ì¥ëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "    model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "    model_path = \"model/best_conv_model.pth\" # í•™ìŠµì—ì„œ ì €ì¥ëœ ê²½ë¡œ\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    print(f\"ëª¨ë¸ {model_path} ë¡œë“œ ì™„ë£Œ.\")\n",
    "\n",
    "    # 3. TTA ì¶”ë¡  ì‹¤í–‰ (Inference ì„¹ì…˜ ì½”ë“œ ì¬í™œìš©)\n",
    "    tta_preds_list = []\n",
    "    with torch.no_grad():\n",
    "        for image, _ in tqdm(holdout_tta_loader, desc=\"TTA ì¶”ë¡  ì¤‘\"):\n",
    "            image = image.to(device)\n",
    "            \n",
    "            # TTA 0: ì›ë³¸ ì˜ˆì¸¡\n",
    "            pred_orig = model(image)\n",
    "\n",
    "            # TTA 1: ì¢Œìš° ë°˜ì „\n",
    "            image_hflip = torch.flip(image, dims=[-1]) \n",
    "            pred_hflip = model(image_hflip)\n",
    "            \n",
    "            # TTA 2: 90ë„ íšŒì „\n",
    "            image_rot90 = torch.rot90(image, k=1, dims=[-2, -1])\n",
    "            pred_rot90 = model(image_rot90)\n",
    "\n",
    "            # 3ê°œ ì˜ˆì¸¡ì˜ í™•ë¥ (softmax)ì„ í‰ê· ëƒ„\n",
    "            avg_batch_pred = (pred_orig.softmax(dim=1) + \n",
    "                              pred_hflip.softmax(dim=1) + \n",
    "                              pred_rot90.softmax(dim=1)) / 3.0\n",
    "            \n",
    "            tta_preds_list.append(avg_batch_pred.cpu().numpy())\n",
    "    \n",
    "    # (314, 17) í¬ê¸°ì˜ ë°°ì—´ë¡œ í•©ì¹˜ê¸°\n",
    "    final_tta_preds_array = np.concatenate(tta_preds_list, axis=0)\n",
    "\n",
    "    # 4. TTA ì ìš© ì ìˆ˜ ê³„ì‚°\n",
    "    # ìµœì¢… ì˜ˆì¸¡ ë¼ë²¨ (ê°€ì¥ í™•ë¥  ë†’ì€ ê²ƒ)\n",
    "    final_tta_labels = np.argmax(final_tta_preds_array, axis=1)\n",
    "    \n",
    "    # ì‹¤ì œ ì •ë‹µ ë¼ë²¨\n",
    "    true_labels = holdout_df['target'].values\n",
    "    \n",
    "    # Macro F1 ìŠ¤ì½”ì–´ ê³„ì‚°\n",
    "    tta_f1_score = f1_score(true_labels, final_tta_labels, average='macro')\n",
    "    tta_acc_score = accuracy_score(true_labels, final_tta_labels)\n",
    "\n",
    "    print(\"\\n--- TTA ì ìš© 'ë¯¸ë‹ˆ ë¦¬ë”ë³´ë“œ' ìµœì¢… ì ìˆ˜ ---\")\n",
    "    print(f\"âœ… TTA ì ìš© Macro F1: {tta_f1_score:.4f}\")\n",
    "    print(f\"   (TTA ì ìš© Accuracy: {tta_acc_score:.4f})\")\n",
    "    \n",
    "    # í™€ë“œì•„ì›ƒ ì˜ˆì¸¡ í™•ë¥  ì €ì¥\n",
    "    np.save(\"npy/conv_holdout_preds.npy\", final_tta_preds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ model/best_conv_model_old.pth ë¡œë“œ ì™„ë£Œ.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA ì¶”ë¡  ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 197/197 [00:25<00:00,  7.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNeXt í‰ê·  í™•ë¥  ì €ì¥ ì™„ë£Œ!\n",
      "ì¶”ë¡  ì™„ë£Œ. ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tst_df = pd.read_csv(\"datasets_fin/sample_submission.csv\")\n",
    "tst_dataset = ImageDataset(\n",
    "    tst_df,\n",
    "    \"datasets_fin/test/\",\n",
    "    transform=tst_transform  # Test ì…‹ì—ëŠ” ì¦ê°•ì´ ì—†ëŠ” val_transform ì‚¬ìš©\n",
    ")\n",
    "\n",
    "tst_loader = DataLoader(\n",
    "    tst_dataset,\n",
    "    batch_size=BATCH_SIZE * 2,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "# 2. ì €ì¥ëœ ë² ìŠ¤íŠ¸ ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)\n",
    "model_path = \"model/best_conv_model_old.pth\" # í•™ìŠµì—ì„œ ì €ì¥ëœ ê²½ë¡œ\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "print(f\"ëª¨ë¸ {model_path} ë¡œë“œ ì™„ë£Œ.\")\n",
    "\n",
    "# 3. TTA ì¶”ë¡  ì‹¤í–‰ (Inference ì„¹ì…˜ ì½”ë“œ ì¬í™œìš©)\n",
    "tta_preds_list = []\n",
    "with torch.no_grad():\n",
    "    for image, _ in tqdm(tst_loader, desc=\"TTA ì¶”ë¡  ì¤‘\"):\n",
    "        image = image.to(device)\n",
    "        \n",
    "        # TTA 0: ì›ë³¸ ì˜ˆì¸¡\n",
    "        pred_orig = model(image)\n",
    "\n",
    "        # TTA 1: ì¢Œìš° ë°˜ì „\n",
    "        image_hflip = torch.flip(image, dims=[-1]) \n",
    "        pred_hflip = model(image_hflip)\n",
    "        \n",
    "        # TTA 2: 90ë„ íšŒì „\n",
    "        image_rot90 = torch.rot90(image, k=1, dims=[-2, -1])\n",
    "        pred_rot90 = model(image_rot90)\n",
    "\n",
    "        # 3ê°œ ì˜ˆì¸¡ì˜ í™•ë¥ (softmax)ì„ í‰ê· ëƒ„\n",
    "        avg_batch_pred = (pred_orig.softmax(dim=1) + \n",
    "                            pred_hflip.softmax(dim=1) + \n",
    "                            pred_rot90.softmax(dim=1)) / 3.0\n",
    "        \n",
    "        tta_preds_list.append(avg_batch_pred.cpu().numpy())\n",
    "\n",
    "# 4. ìµœì¢… ì˜ˆì¸¡ ë¼ë²¨ ìƒì„±\n",
    "final_tta_preds_array = np.concatenate(tta_preds_list, axis=0)\n",
    "\n",
    "np.save(\"npy/conv_final_preds.npy\", final_tta_preds_array) \n",
    "print(\"ConvNeXt í‰ê·  í™•ë¥  ì €ì¥ ì™„ë£Œ!\")\n",
    "\n",
    "final_tta_labels = np.argmax(final_tta_preds_array, axis=1)\n",
    "\n",
    "# 5. [âœ… ìˆ˜ì •ë¨] F1 ìŠ¤ì½”ì–´ ê³„ì‚° ë¶€ë¶„ ***ì™„ì „ ì‚­ì œ***\n",
    "# (ìš°ë¦¬ëŠ” 'ì§„ì§œ í…ŒìŠ¤íŠ¸ ë°ì´í„°'ì˜ ì •ë‹µì„ ëª¨ë¥´ë¯€ë¡œ ê³„ì‚° ë¶ˆê°€ëŠ¥)\n",
    "print(\"ì¶”ë¡  ì™„ë£Œ. ì œì¶œ íŒŒì¼ ìƒì„± ì¤‘...\")\n",
    "\n",
    "# 6. [âœ… ìˆ˜ì •ë¨] ì œì¶œ íŒŒì¼ ìƒì„±\n",
    "pred_df = tst_df.copy()\n",
    "# [ì¤‘ìš”!] 'ê°€ì§œ ì •ë‹µ'(true_labels)ì´ ì•„ë‹Œ, 'ëª¨ë¸ì˜ ì˜ˆì¸¡'(final_tta_labels)ì„ ë„£ì–´ì•¼ í•¨\n",
    "pred_df['target'] = final_tta_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 12  5 ...  8  0 12]\n"
     ]
    }
   ],
   "source": [
    "print(final_tta_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (tst_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file created!\n"
     ]
    }
   ],
   "source": [
    "pred_df.to_csv(\"submission/pred13.csv\", index=False)\n",
    "print(\"Submission file created!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
