{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0da3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 8. Learning Rate Scheduler (원본 유지)\n",
    "# ===============================\n",
    "class WarmupCosineScheduler:\n",
    "    def __init__(self, optimizer, warmup_epochs, total_epochs, max_lr, min_lr):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.total_epochs = total_epochs\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        \n",
    "    def step(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            lr = self.max_lr * (epoch + 1) / self.warmup_epochs\n",
    "        else:\n",
    "            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)\n",
    "            lr = self.min_lr + (self.max_lr - self.min_lr) * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        \n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9fdba8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 9. 모델 생성 (원본 유지)\n",
    "# ===============================\n",
    "def create_model(model_name, num_classes, pretrained=True):\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=pretrained,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03ea8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 10. 학습 함수 (원본 유지)\n",
    "# ===============================\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1} - Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item(), 'acc': 100 * correct / total})\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea9fd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 11. 검증 함수 (원본 유지)\n",
    "# ===============================\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Validating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b9518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 13. [NEW] OCR 모델 학습 함수 (Track 2)\n",
    "# ===============================\n",
    "def clean_text(text):\n",
    "    \"\"\"간단한 텍스트 클리닝 (특수문자 제거)\"\"\"\n",
    "    # 한국어, 영어, 숫자, 공백만 남김\n",
    "    return re.sub(r'[^A-Za-z0-9가-힣\\s]', '', text)\n",
    "\n",
    "def get_ocr_text_from_path(reader, img_path):\n",
    "    \"\"\"EasyOCR을 사용해 이미지 경로에서 텍스트 추출\"\"\"\n",
    "    try:\n",
    "        # detail=0은 텍스트만 리스트로 반환\n",
    "        text_list = reader.readtext(img_path, detail=0)\n",
    "        full_text = ' '.join(text_list)\n",
    "        return clean_text(full_text)\n",
    "    except Exception as e:\n",
    "        # print(f\"Warning: OCR 실패 {img_path} - {e}\")\n",
    "        return \"\" # OCR 실패 시 빈 문자열 반환\n",
    "\n",
    "def train_ocr_model():\n",
    "    \"\"\"\n",
    "    Train.csv의 모든 이미지를 읽어 OCR 텍스트 분류기를 학습시킵니다.\n",
    "    학습된 모델은 'ocr_model.joblib'로 저장하고, 캐시된 파일이 있으면 로드합니다.\n",
    "    \"\"\"\n",
    "    ocr_model_path = 'ocr_model.joblib'\n",
    "    \n",
    "    # EasyOCR 리더 초기화 (GPU 사용)\n",
    "    ocr_reader = easyocr.Reader(config.ocr_lang, gpu=True)\n",
    "    \n",
    "    if os.path.exists(ocr_model_path):\n",
    "        print(f\"Loading cached OCR model from {ocr_model_path}...\")\n",
    "        ocr_pipeline = joblib.load(ocr_model_path)\n",
    "        return ocr_reader, ocr_pipeline\n",
    "\n",
    "    print(f\"No cached model found. Training new OCR model...\")\n",
    "    \n",
    "    # 1. 학습 데이터 로드\n",
    "    train_df = pd.read_csv(config.train_csv)\n",
    "    \n",
    "    # 2. 모든 학습 이미지에서 텍스트 추출\n",
    "    X_texts = []\n",
    "    y_labels = []\n",
    "    \n",
    "    pbar = tqdm(train_df.itertuples(), total=len(train_df), desc=\"Running OCR on train data\")\n",
    "    for row in pbar:\n",
    "        img_id = row.ID\n",
    "        label = row.target\n",
    "        img_path = os.path.join(config.train_img_dir, img_id)\n",
    "        \n",
    "        ocr_text = get_ocr_text_from_path(ocr_reader, img_path)\n",
    "        \n",
    "        X_texts.append(ocr_text)\n",
    "        y_labels.append(label)\n",
    "    \n",
    "    print(f\"OCR extraction complete. Found text in {sum([1 for t in X_texts if t])}/{len(X_texts)} images.\")\n",
    "    \n",
    "    # 3. Scikit-learn 파이프라인 생성 (TF-IDF + 로지스틱 회귀)\n",
    "    # n-gram (1, 2)를 사용하여 단어 및 연속된 두 단어(bigram)를 피처로 사용\n",
    "    # max_features로 피처 수 제한 (메모리 관리)\n",
    "    ocr_pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(ngram_range=(1, 2), max_features=10000, token_pattern=r'\\b\\w+\\b')),\n",
    "        ('clf', LogisticRegression(solver='liblinear', C=1.0, random_state=42, multi_class='auto'))\n",
    "    ])\n",
    "    \n",
    "    # 4. 모델 학습\n",
    "    print(\"Training TF-IDF + Logistic Regression model...\")\n",
    "    ocr_pipeline.fit(X_texts, y_labels)\n",
    "    \n",
    "    # 5. 모델 저장\n",
    "    joblib.dump(ocr_pipeline, ocr_model_path)\n",
    "    print(f\"OCR model saved to {ocr_model_path}\")\n",
    "    \n",
    "    return ocr_reader, ocr_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffdf88a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 14. 학습 파이프라인 (원본 유지)\n",
    "# (Vision 모델만 학습)\n",
    "# ===============================\n",
    "def run_training_pipeline():\n",
    "    \n",
    "    # --- 1단계: 원본 데이터로 초기 학습 ---\n",
    "    print(f'\\n{\"=\"*50}')\n",
    "    print(f'STAGE 1: Initial Training on Labeled Data (Vision Track)')\n",
    "    print(f'{\"=\"*50}')\n",
    "\n",
    "    train_df = pd.read_csv(config.train_csv)\n",
    "    \n",
    "    train_fold_df, valid_fold_df = train_test_split(\n",
    "        train_df,\n",
    "        test_size=config.val_split_ratio,\n",
    "        random_state=42,\n",
    "        stratify=train_df['target']\n",
    "    )\n",
    "    train_fold_df = train_fold_df.reset_index(drop=True)\n",
    "    valid_fold_df = valid_fold_df.reset_index(drop=True)\n",
    "\n",
    "    print(f\"Stage 1: Train data: {len(train_fold_df)}, Valid data: {len(valid_fold_df)}\")\n",
    "\n",
    "    train_dataset = DocumentDataset(\n",
    "        train_fold_df, \n",
    "        config.train_img_dir,\n",
    "        config.test_img_dir,\n",
    "        transform=get_train_transform(config.img_size)\n",
    "    )\n",
    "    valid_dataset = DocumentDataset(\n",
    "        valid_fold_df, \n",
    "        config.train_img_dir,\n",
    "        config.test_img_dir,\n",
    "        transform=get_valid_transform(config.img_size)\n",
    "    )\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=config.batch_size, shuffle=True, \n",
    "        num_workers=config.num_workers, pin_memory=True\n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, batch_size=config.batch_size, shuffle=False, \n",
    "        num_workers=config.num_workers, pin_memory=True\n",
    "    )\n",
    "    \n",
    "    model = create_model(config.model_name, config.num_classes, pretrained=True).to(config.device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=config.max_lr, weight_decay=1e-4)\n",
    "    scheduler = WarmupCosineScheduler(\n",
    "        optimizer, warmup_epochs=config.warmup_epochs, total_epochs=config.epochs,\n",
    "        max_lr=config.max_lr, min_lr=config.min_lr\n",
    "    )\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    for epoch in range(config.epochs):\n",
    "        current_lr = scheduler.step(epoch)\n",
    "        train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer, config.device, epoch)\n",
    "        val_loss, val_acc = validate(model, valid_loader, criterion, config.device)\n",
    "        \n",
    "        print(f'Stage 1 - Epoch {epoch+1}/{config.epochs}')\n",
    "        print(f'LR: {current_lr:.6f}')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "        print(f'Valid Loss: {val_loss:.4f}, Valid Acc: {val_acc:.2f}%')\n",
    "        \n",
    "        if config.use_wandb:\n",
    "            wandb.log({\n",
    "                'stage1/train_loss': train_loss, 'stage1/train_acc': train_acc,\n",
    "                'stage1/val_loss': val_loss, 'stage1/val_acc': val_acc,\n",
    "                'stage1/learning_rate': current_lr, 'epoch_stage1': epoch + 1\n",
    "            })\n",
    "        \n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save(model.state_dict(), 'best_model_stage1.pth')\n",
    "            print(f'✓ Best Stage 1 model saved! (Val Acc: {val_acc:.2f}%)')\n",
    "\n",
    "    print(f'\\nStage 1 Best Validation Accuracy: {best_val_acc:.2f}%')\n",
    "\n",
    "    # --- 2단계: 의사 라벨링 및 재학습 ---\n",
    "    if config.use_pseudo_labeling:\n",
    "        \n",
    "        # 2-A: 의사 라벨 생성 (Vision 모델만 사용)\n",
    "        print(f'\\n{\"=\"*50}')\n",
    "        print(f'STAGE 2: Generating Pseudo-Labels (Vision Track)')\n",
    "        print(f'{\"=\"*50}')\n",
    "        \n",
    "        model.load_state_dict(torch.load('best_model_stage1.pth'))\n",
    "        \n",
    "        submission_df = pd.read_csv(config.submission_csv)\n",
    "        pseudo_gen_dataset = TestDataset(\n",
    "            submission_df, \n",
    "            config.test_img_dir, \n",
    "            transform=get_valid_transform(config.img_size)\n",
    "        )\n",
    "        pseudo_gen_loader = DataLoader(\n",
    "            pseudo_gen_dataset, batch_size=config.batch_size, shuffle=False, \n",
    "            num_workers=config.num_workers, pin_memory=True\n",
    "        )\n",
    "        \n",
    "        pseudo_label_df = generate_pseudo_labels(\n",
    "            model, pseudo_gen_loader, config.device, config.pseudo_label_threshold\n",
    "        )\n",
    "        print(f'Generated {len(pseudo_label_df)} pseudo-labels with threshold >= {config.pseudo_label_threshold}')\n",
    "        if config.use_wandb:\n",
    "            wandb.log({'pseudo_label_count': len(pseudo_label_df)})\n",
    "\n",
    "        if len(pseudo_label_df) == 0:\n",
    "            print(\"No pseudo-labels generated. Skipping re-training.\")\n",
    "            return\n",
    "\n",
    "        # 2-B: 의사 라벨과 함께 재학습 (Vision 모델)\n",
    "        print(f'\\n{\"=\"*50}')\n",
    "        print(f'STAGE 3: Re-training with Pseudo-Labels (Vision Track)')\n",
    "        print(f'{\"=\"*50}')\n",
    "\n",
    "        combined_train_df = pd.concat([train_fold_df, pseudo_label_df], ignore_index=True)\n",
    "        print(f\"Stage 3: Combined Train data: {len(combined_train_df)}, Valid data: {len(valid_fold_df)}\")\n",
    "\n",
    "        train_dataset_pseudo = DocumentDataset(\n",
    "            combined_train_df, \n",
    "            config.train_img_dir,\n",
    "            config.test_img_dir, \n",
    "            transform=get_train_transform(config.img_size)\n",
    "        )\n",
    "        \n",
    "        train_loader_pseudo = DataLoader(\n",
    "            train_dataset_pseudo, batch_size=config.batch_size, shuffle=True, \n",
    "            num_workers=config.num_workers, pin_memory=True\n",
    "        )\n",
    "        \n",
    "        model_pseudo = create_model(config.model_name, config.num_classes, pretrained=True).to(config.device)\n",
    "        criterion_pseudo = nn.CrossEntropyLoss()\n",
    "        optimizer_pseudo = optim.AdamW(model_pseudo.parameters(), lr=config.max_lr, weight_decay=1e-4)\n",
    "        scheduler_pseudo = WarmupCosineScheduler(\n",
    "            optimizer_pseudo, warmup_epochs=config.warmup_epochs, total_epochs=config.epochs,\n",
    "            max_lr=config.max_lr, min_lr=config.min_lr\n",
    "        )\n",
    "        \n",
    "        best_val_acc_pseudo = 0.0\n",
    "        for epoch in range(config.epochs):\n",
    "            current_lr = scheduler_pseudo.step(epoch)\n",
    "            train_loss, train_acc = train_one_epoch(\n",
    "                model_pseudo, train_loader_pseudo, criterion_pseudo, optimizer_pseudo, config.device, epoch\n",
    "            )\n",
    "            val_loss, val_acc = validate(model_pseudo, valid_loader, criterion_pseudo, config.device)\n",
    "            \n",
    "            print(f'Stage 3 - Epoch {epoch+1}/{config.epochs}')\n",
    "            print(f'LR: {current_lr:.6f}')\n",
    "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Valid Loss: {val_loss:.4f}, Valid Acc: {val_acc:.2f}%')\n",
    "            \n",
    "            if config.use_wandb:\n",
    "                wandb.log({\n",
    "                    'stage3/train_loss': train_loss, 'stage3/train_acc': train_acc,\n",
    "                    'stage3/val_loss': val_loss, 'stage3/val_acc': val_acc,\n",
    "                    'stage3/learning_rate': current_lr, 'epoch_stage3': epoch + 1\n",
    "                })\n",
    "            \n",
    "            if val_acc > best_val_acc_pseudo:\n",
    "                best_val_acc_pseudo = val_acc\n",
    "                torch.save(model_pseudo.state_dict(), 'best_model_stage2_pseudo.pth')\n",
    "                print(f'✓ Best Stage 3 (Pseudo) model saved! (Val Acc: {val_acc:.2f}%)')\n",
    "        \n",
    "        print(f'\\nStage 3 Best Validation Accuracy: {best_val_acc_pseudo:.2f}%')\n",
    "        if config.use_wandb:\n",
    "            wandb.log({'final_best_val_acc': best_val_acc_pseudo})\n",
    "\n",
    "    else:\n",
    "        print(\"Pseudo-labeling disabled. Using Stage 1 model for inference.\")\n",
    "        if config.use_wandb:\n",
    "            wandb.log({'final_best_val_acc': best_val_acc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513839c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 15. 테스트 예측 (TTA + OCR 앙상블 적용, 수정됨)\n",
    "# ===============================\n",
    "def predict_with_tta_ocr_ensemble(ocr_reader, ocr_pipeline):\n",
    "    \"\"\"TTA(Vision)와 OCR(Text)을 앙상블하여 테스트 예측\"\"\"\n",
    "    submission_df = pd.read_csv(config.submission_csv)\n",
    "    \n",
    "    # --- Track 1: Vision 모델 로드 ---\n",
    "    tta_transforms = get_tta_transforms(config.img_size)\n",
    "    \n",
    "    vision_model = create_model(config.model_name, config.num_classes, pretrained=False)\n",
    "    \n",
    "    if config.use_pseudo_labeling and os.path.exists('best_model_stage2_pseudo.pth'):\n",
    "        model_path = 'best_model_stage2_pseudo.pth'\n",
    "        print(\"Loading Stage 3 (Pseudo-Label) model for Vision Track.\")\n",
    "    else:\n",
    "        model_path = 'best_model_stage1.pth'\n",
    "        print(\"Loading Stage 1 model for Vision Track.\")\n",
    "        \n",
    "    vision_model.load_state_dict(torch.load(model_path))\n",
    "    vision_model = vision_model.to(config.device)\n",
    "    vision_model.eval()\n",
    "    \n",
    "    # --- Track 2: OCR 모델은 이미 'ocr_pipeline'으로 로드됨 ---\n",
    "    print(\"Using pre-trained OCR model for Text Track.\")\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    pbar = tqdm(submission_df['ID'], desc='Predicting with 2-Track Ensemble')\n",
    "    for img_name in pbar:\n",
    "        img_path = os.path.join(config.test_img_dir, img_name)\n",
    "        \n",
    "        # --- Track 1: Vision TTA 예측 ---\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image_np = np.array(image)\n",
    "        \n",
    "        tta_preds_for_image = []\n",
    "        with torch.no_grad():\n",
    "            for transform in tta_transforms:\n",
    "                augmented = transform(image=image_np)\n",
    "                img_tensor = augmented['image'].unsqueeze(0).to(config.device)\n",
    "                \n",
    "                outputs = vision_model(img_tensor)\n",
    "                probs = torch.softmax(outputs, dim=1)\n",
    "                tta_preds_for_image.append(probs.cpu().numpy())\n",
    "        \n",
    "        # TTA 평균 (Shape: (17,))\n",
    "        vision_probs = np.mean(tta_preds_for_image, axis=0)\n",
    "        vision_probs = np.squeeze(vision_probs) # (1, 17) -> (17,)\n",
    "        \n",
    "        # --- Track 2: OCR 예측 ---\n",
    "        # TTA와 달리 원본 이미지 1장에 대해서만 OCR 수행\n",
    "        ocr_text = get_ocr_text_from_path(ocr_reader, img_path)\n",
    "        \n",
    "        # .predict_proba는 (n_samples, n_classes) 형태의 배열 반환. [0]으로 첫 번째(유일한) 샘플 선택\n",
    "        # (Shape: (17,))\n",
    "        ocr_probs = ocr_pipeline.predict_proba([ocr_text])[0]\n",
    "        \n",
    "        # --- 앙상블 ---\n",
    "        # 두 확률 분포를 가중 평균\n",
    "        final_probs = (config.ensemble_vision_weight * vision_probs) + \\\n",
    "                      (config.ensemble_ocr_weight * ocr_probs)\n",
    "        \n",
    "        predicted_class = np.argmax(final_probs)\n",
    "        all_predictions.append(predicted_class)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission_df['target'] = all_predictions\n",
    "    submission_filename = 'submission_ensemble.csv'\n",
    "    submission_df.to_csv(submission_filename, index=False)\n",
    "    print(f'Submission file saved as {submission_filename}!')\n",
    "    \n",
    "    if config.use_wandb:\n",
    "        wandb.save(submission_filename)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
