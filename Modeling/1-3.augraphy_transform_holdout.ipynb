{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ee2d0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: timm in /workspace/.venv/lib/python3.10/site-packages (1.0.22)\n",
      "Requirement already satisfied: torch in /workspace/.venv/lib/python3.10/site-packages (from timm) (2.9.0)\n",
      "Requirement already satisfied: torchvision in /workspace/.venv/lib/python3.10/site-packages (from timm) (0.24.0)\n",
      "Requirement already satisfied: pyyaml in /workspace/.venv/lib/python3.10/site-packages (from timm) (6.0.3)\n",
      "Requirement already satisfied: huggingface_hub in /workspace/.venv/lib/python3.10/site-packages (from timm) (1.1.2)\n",
      "Requirement already satisfied: safetensors in /workspace/.venv/lib/python3.10/site-packages (from timm) (0.6.2)\n",
      "Requirement already satisfied: filelock in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (25.0)\n",
      "Requirement already satisfied: shellingham in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /workspace/.venv/lib/python3.10/site-packages (from huggingface_hub->timm) (4.15.0)\n",
      "Requirement already satisfied: anyio in /workspace/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (4.11.0)\n",
      "Requirement already satisfied: certifi in /workspace/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (2025.10.5)\n",
      "Requirement already satisfied: httpcore==1.* in /workspace/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (1.0.9)\n",
      "Requirement already satisfied: idna in /workspace/.venv/lib/python3.10/site-packages (from httpx<1,>=0.23.0->huggingface_hub->timm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /workspace/.venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub->timm) (0.16.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /workspace/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspace/.venv/lib/python3.10/site-packages (from anyio->httpx<1,>=0.23.0->huggingface_hub->timm) (1.3.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /workspace/.venv/lib/python3.10/site-packages (from torch->timm) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.venv/lib/python3.10/site-packages (from jinja2->torch->timm) (3.0.3)\n",
      "Requirement already satisfied: numpy in /workspace/.venv/lib/python3.10/site-packages (from torchvision->timm) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /workspace/.venv/lib/python3.10/site-packages (from torchvision->timm) (12.0.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /workspace/.venv/lib/python3.10/site-packages (from typer-slim->huggingface_hub->timm) (8.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: albumentations in /workspace/.venv/lib/python3.10/site-packages (2.0.8)\n",
      "Requirement already satisfied: augraphy in /workspace/.venv/lib/python3.10/site-packages (8.2.6)\n",
      "Requirement already satisfied: torch in /workspace/.venv/lib/python3.10/site-packages (2.9.0)\n",
      "Requirement already satisfied: opencv-python in /workspace/.venv/lib/python3.10/site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /workspace/.venv/lib/python3.10/site-packages (from albumentations) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /workspace/.venv/lib/python3.10/site-packages (from albumentations) (1.15.3)\n",
      "Requirement already satisfied: PyYAML in /workspace/.venv/lib/python3.10/site-packages (from albumentations) (6.0.3)\n",
      "Requirement already satisfied: pydantic>=2.9.2 in /workspace/.venv/lib/python3.10/site-packages (from albumentations) (2.12.4)\n",
      "Requirement already satisfied: albucore==0.0.24 in /workspace/.venv/lib/python3.10/site-packages (from albumentations) (0.0.24)\n",
      "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /workspace/.venv/lib/python3.10/site-packages (from albumentations) (4.12.0.88)\n",
      "Requirement already satisfied: stringzilla>=3.10.4 in /workspace/.venv/lib/python3.10/site-packages (from albucore==0.0.24->albumentations) (4.2.3)\n",
      "Requirement already satisfied: simsimd>=5.9.2 in /workspace/.venv/lib/python3.10/site-packages (from albucore==0.0.24->albumentations) (6.5.3)\n",
      "Requirement already satisfied: matplotlib>=3.4.3 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (3.10.7)\n",
      "Requirement already satisfied: numba>=0.57.0 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (0.62.1)\n",
      "Requirement already satisfied: Pillow>=8.0.0 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (12.0.0)\n",
      "Requirement already satisfied: requests>=2.25.1 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (2.32.5)\n",
      "Requirement already satisfied: scikit-image>=0.18.1 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (0.25.2)\n",
      "Requirement already satisfied: scikit-learn>=0.23.2 in /workspace/.venv/lib/python3.10/site-packages (from augraphy) (1.7.2)\n",
      "Requirement already satisfied: filelock in /workspace/.venv/lib/python3.10/site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /workspace/.venv/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /workspace/.venv/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /workspace/.venv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /workspace/.venv/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /workspace/.venv/lib/python3.10/site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /workspace/.venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /workspace/.venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /workspace/.venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /workspace/.venv/lib/python3.10/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /workspace/.venv/lib/python3.10/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /workspace/.venv/lib/python3.10/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /workspace/.venv/lib/python3.10/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /workspace/.venv/lib/python3.10/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /workspace/.venv/lib/python3.10/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /workspace/.venv/lib/python3.10/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /workspace/.venv/lib/python3.10/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /workspace/.venv/lib/python3.10/site-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /workspace/.venv/lib/python3.10/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /workspace/.venv/lib/python3.10/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /workspace/.venv/lib/python3.10/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /workspace/.venv/lib/python3.10/site-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (25.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /workspace/.venv/lib/python3.10/site-packages (from matplotlib>=3.4.3->augraphy) (2.9.0.post0)\n",
      "Requirement already satisfied: llvmlite<0.46,>=0.45.0dev0 in /workspace/.venv/lib/python3.10/site-packages (from numba>=0.57.0->augraphy) (0.45.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspace/.venv/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /workspace/.venv/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /workspace/.venv/lib/python3.10/site-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/.venv/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib>=3.4.3->augraphy) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspace/.venv/lib/python3.10/site-packages (from requests>=2.25.1->augraphy) (2025.10.5)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /workspace/.venv/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (2.37.2)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /workspace/.venv/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (2025.5.10)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in /workspace/.venv/lib/python3.10/site-packages (from scikit-image>=0.18.1->augraphy) (0.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /workspace/.venv/lib/python3.10/site-packages (from scikit-learn>=0.23.2->augraphy) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /workspace/.venv/lib/python3.10/site-packages (from scikit-learn>=0.23.2->augraphy) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /workspace/.venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspace/.venv/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: numpy in /workspace/.venv/lib/python3.10/site-packages (2.2.6)\n",
      "Requirement already satisfied: pandas in /workspace/.venv/lib/python3.10/site-packages (2.3.3)\n",
      "Requirement already satisfied: scikit-learn in /workspace/.venv/lib/python3.10/site-packages (1.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /workspace/.venv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /workspace/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /workspace/.venv/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /workspace/.venv/lib/python3.10/site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /workspace/.venv/lib/python3.10/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /workspace/.venv/lib/python3.10/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: six>=1.5 in /workspace/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install timm\n",
    "%pip install albumentations augraphy torch opencv-python\n",
    "%pip install --upgrade numpy pandas scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fb27a3",
   "metadata": {},
   "source": [
    "# 1. 라이브러리 로드 및 클래스와 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fbcfdf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import timm\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import augraphy as aug\n",
    "import albumentations as A\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# ============================\n",
    "# 시드 고정\n",
    "# ============================\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "716503fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 데이터셋\n",
    "# ============================\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, \n",
    "                 hard_paper_transform=None,\n",
    "                 easy_paper_transform=None, \n",
    "                 non_paper_transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        # self.transform = transform\n",
    "\n",
    "        # 1. 종이/비종이/어려운종이 이미지에 따라 다른 증강을 적용할 수 있도록 분리\n",
    "        self.hard_paper_transform = hard_paper_transform\n",
    "        self.easy_paper_transform = easy_paper_transform\n",
    "        self.non_paper_transform = non_paper_transform\n",
    "        \n",
    "        # 2. 타겟 그룹을 set으로 정의 (빠른 조회를 위해)\n",
    "        # 2.1 '어려운 종이'\n",
    "        self.hard_paper_targets = {3, 4, 6, 7, 14, 10}\n",
    "        \n",
    "        # 2.2 '쉬운 종이'\n",
    "        # (기존 '종이' 그룹 [1,3,4,6,7,11,12,14,10,13] 에서 '어려운' 그룹을 제외)\n",
    "        self.easy_paper_targets = {1, 11, 12, 13}\n",
    "\n",
    "        # 3. K-Fold로 잘린 df를 받자마자 인덱스를 0부터 리셋합니다.\n",
    "        df_reset = df.reset_index(drop=True)\n",
    "        self.image_ids = df_reset['ID'].values\n",
    "        self.labels = df_reset['target'].values\n",
    "        self.length = len(df_reset)\n",
    "\n",
    "    def __len__(self):\n",
    "        # __init__에서 저장한 데이터셋의 길이를 반환합니다.\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # DataLoader는 0부터 (self.length - 1)까지의 idx를 전달합니다.\n",
    "        \n",
    "        try:\n",
    "            # 3. .iloc가 아닌, 안전한 numpy 배열에서 idx로 데이터를 가져옵니다.\n",
    "            img_id = self.image_ids[idx]\n",
    "            label = self.labels[idx]\n",
    "        except IndexError:\n",
    "            print(f\"!!! DATASET INDEX ERROR: idx={idx}, len={self.length} !!!\")\n",
    "            raise\n",
    "\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        image = cv2.imread(img_path)\n",
    "        \n",
    "        # 이미지 파일을 읽지 못한 경우 에러 처리\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"이미지 파일을 찾을 수 없거나 읽을 수 없습니다: {img_path}\")\n",
    "\n",
    "        # BGR -> RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "        # --- 레이블에 따라 다른 Transform 적용 ---\n",
    "        transform_to_apply = None\n",
    "        \n",
    "        if label in self.hard_paper_targets:\n",
    "            # 1. '어려운 종이'\n",
    "            transform_to_apply = self.hard_paper_transform\n",
    "        elif label in self.easy_paper_targets:\n",
    "            # 2. '쉬운 종이'\n",
    "            transform_to_apply = self.easy_paper_transform\n",
    "        else:\n",
    "            # 3. '비종이'\n",
    "            transform_to_apply = self.non_paper_transform\n",
    "        \n",
    "        # 5. 선택된 Transform 적용\n",
    "        if transform_to_apply:\n",
    "            augmented = transform_to_apply(image=image)\n",
    "            image = augmented['image']\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81066b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Mixup\n",
    "# ============================\n",
    "def mixup_data(x, y, alpha=1.0, device='cuda'):\n",
    "    \"\"\"\n",
    "    배치 내에서 MixUp을 수행합니다.\n",
    "    x: 이미지 배치 (images)\n",
    "    y: 레이블 배치 (labels)\n",
    "    alpha: Beta 분포의 하이퍼파라미터 (1.0일 때 0~1 사이의 균일한 분포와 유사)\n",
    "    \"\"\"\n",
    "    if alpha > 0:\n",
    "        # 람다(lambda) 값을 Beta 분포에서 샘플링\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        # alpha=0이면 MixUp을 적용하지 않음\n",
    "        lam = 1\n",
    "\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    # 섞을 대상 인덱스를 랜덤하게 섞음\n",
    "    # (예: [0, 1, 2, 3] -> [2, 0, 3, 1])\n",
    "    index = torch.randperm(batch_size).to(device)\n",
    "\n",
    "    # 이미지를 섞음 (x_a * lam + x_b * (1-lam))\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    \n",
    "    # 레이블도 섞을 준비 (y_a, y_b)\n",
    "    y_a, y_b = y, y[index]\n",
    "    \n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, preds, y_a, y_b, lam):\n",
    "    \"\"\"\n",
    "    MixUp된 예측값(preds)에 대한 손실(loss)을 계산합니다.\n",
    "    criterion: 기본 손실 함수 (예: nn.CrossEntropyLoss)\n",
    "    preds: 모델의 예측값 (logits)\n",
    "    y_a, y_b: 섞인 두 원본 레이블\n",
    "    lam: MixUp 람다 값\n",
    "    \"\"\"\n",
    "    # 손실 계산: loss = (loss_a * lam) + (loss_b * (1-lam))\n",
    "    return lam * criterion(preds, y_a) + (1 - lam) * criterion(preds, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f52a0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Epoch 학습 (MixUp 포함)\n",
    "# ============================\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device, mixup_alpha):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for images, labels in tqdm(loader, desc=\"Train\"):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # MixUp 적용\n",
    "        mixed_images, labels_a, labels_b, lam = mixup_data(images, labels, mixup_alpha, device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(mixed_images)\n",
    "        loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "318c951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# Epoch 검증 함수 (F1 스코어)\n",
    "# ============================\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Valid\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "    # F1 스코어 계산 (Macro F1)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro')\n",
    "    return total_loss / len(loader), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ade984e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 학습 조기 종료\n",
    "# ============================\n",
    "class EarlyStopping:\n",
    "    \"\"\"\n",
    "    Validation F1 스코어를 모니터링하여 학습을 조기 종료시킵니다.\n",
    "    F1 스코어는 높을수록 좋습니다.\n",
    "    \"\"\"\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, path='best_model.pth'):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): F1 스코어가 개선되지 않아도 기다릴 에포크 수\n",
    "            verbose (bool): 조기 종료 또는 개선 시 메시지 출력 여부\n",
    "            delta (float): F1 스코어가 최소 이 값 이상 개선되어야 함\n",
    "            path (str): 최고 성능 모델을 저장할 경로\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_f1, model):\n",
    "        # 처음 호출 시 best_score 초기화\n",
    "        if self.best_score is None:\n",
    "            self.best_score = val_f1\n",
    "            self.save_checkpoint(val_f1, model)\n",
    "        \n",
    "        # F1 스코어가 개선되지 않았을 때\n",
    "        elif val_f1 < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        \n",
    "        # F1 스코어가 개선되었을 때\n",
    "        else:\n",
    "            self.best_score = val_f1\n",
    "            self.save_checkpoint(val_f1, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_f1, model):\n",
    "        # 모델 저장\n",
    "        if self.verbose:\n",
    "            print(f'Validation F1 improved ({self.best_score:.6f} -> {val_f1:.6f}). Saving model ...')\n",
    "        torch.save(model.state_dict(), self.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b7479",
   "metadata": {},
   "source": [
    "# 2. Augraphy 파이프라인 생성 (온라인 증강)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbd575c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 384\n",
    "TRAIN_IMG_DIR = \"datasets_fin/train/\"\n",
    "TRAIN_CSV_PATH = \"datasets_fin/train.csv\"\n",
    "MODEL_SAVE_DIR = \"model/\"\n",
    "\n",
    "# ============================\n",
    "# Augraphy 파이프라인\n",
    "# ============================\n",
    "# 표준 종이 문서 ([1,11,12,13])\n",
    "augraphy_pipeline = aug.AugraphyPipeline(\n",
    "    [\n",
    "        # 1. 팩스/복사본처럼 품질 저하 (Test 데이터의 흐릿함/대비 문제)\n",
    "        aug.BadPhotoCopy(\n",
    "            noise_size=(3, 3),        # 노이즈 크기\n",
    "            noise_type=-1,            # 랜덤 노이즈 타입\n",
    "            noise_value=(50, 100), # 노이즈 강도\n",
    "            p=0.5                     # 50% 확률로 적용\n",
    "        ),\n",
    "        \n",
    "        # 2. 잉크/토너 부족 효과\n",
    "        aug.LowInkRandomLines(\n",
    "            use_consistent_lines=False, # 일관된 줄무늬 사용 안 함\n",
    "            count_range=(3, 10), # 잉크 빠진 줄 개수\n",
    "            p=0.4                       # 40% 확률로 적용\n",
    "        ),\n",
    "\n",
    "        # 3. 스캐너 롤러 자국 또는 얼룩\n",
    "        aug.DirtyRollers(\n",
    "            line_width_range=(2, 6),\n",
    "            p=0.3                       # 30% 확률로 적용\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 어려운 종이 문서 ([3,4,6,7,10,14])\n",
    "augraphy_pipeline_hard = aug.AugraphyPipeline(\n",
    "    [\n",
    "        aug.BadPhotoCopy(\n",
    "            noise_size=(2, 4), # 노이즈 크기 증가\n",
    "            noise_value=(40, 80), # 강도 증가\n",
    "            p=0.8 # 확률 50% -> 80%\n",
    "        ),\n",
    "        aug.LowInkRandomLines(\n",
    "            count_range=(5, 15), # 잉크 빠짐 증가\n",
    "            use_consistent_lines=False, \n",
    "            p=0.7 # 확률 40% -> 70%\n",
    "        ),\n",
    "        aug.DirtyRollers(\n",
    "            line_width_range=(3, 8), # 롤러 자국 증가\n",
    "            p=0.6 # 확률 30% -> 60%\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# --- Albumentations의 Lambda로 Augraphy 래핑 ---\n",
    "# Albumentations 파이프라인 내에서 Augraphy를 호출하기 위한 함수\n",
    "# 표준 종이 문서 ([1,11,12,13])\n",
    "def apply_augraphy(image, **kwargs):\n",
    "    \"\"\"\n",
    "    Albumentations가 넘겨준 이미지를 Augraphy 파이프라인에 적용\n",
    "    \"\"\"\n",
    "    # Augraphy는 RGB (H, W, 3) 형태의 uint8 numpy 배열을 기대합니다.\n",
    "    # cv2.imread로 읽었다면 BGR -> RGB 변환이 필요할 수 있지만,\n",
    "    # Pytorch Dataset에서 보통 RGB로 로드하므로 바로 사용 가능\n",
    "    return augraphy_pipeline.augment(image)[\"output\"]\n",
    "\n",
    "# 어려운 종이 문서 ([3,4,6,7,10,14])\n",
    "def apply_augraphy_hard(image, **kwargs):\n",
    "    return augraphy_pipeline_hard.augment(image)[\"output\"]\n",
    "\n",
    "\n",
    "# --- 최종 Albumentations 파이프라인 ---\n",
    "# 표준 종이 문서 ([1,11,12,13])\n",
    "def get_train_transform(img_size=IMG_SIZE):\n",
    "    return A.Compose([\n",
    "        # --- 1. Augraphy 적용 (Lambda 사용) ---\n",
    "        # 50% 확률로 Augraphy의 '더러운' 효과 적용\n",
    "        A.Lambda(image=apply_augraphy, p=0.5),\n",
    "\n",
    "        # --- 2. 기하학적 변형 (Test 데이터의 심한 왜곡 재현) ---\n",
    "        # (가장 중요) 원근 왜곡: 비스듬히 찍힌 효과\n",
    "        A.Perspective(\n",
    "            scale=(0.05, 0.1),  # 왜곡 강도\n",
    "            pad_mode=cv2.BORDER_CONSTANT, # 빈 공간 채우기\n",
    "            pad_val=0,          # 검은색으로 채우기\n",
    "            p=0.7               # 70% 확률로 적용\n",
    "        ),\n",
    "\n",
    "        # 회전: 각도를 크게 줌\n",
    "        A.Rotate(\n",
    "            limit=(-40, 40),      # -40 ~ +40도 사이로 회전\n",
    "            border_mode=cv2.BORDER_CONSTANT,\n",
    "            value=0,\n",
    "            p=0.8                 # 80% 확률로 적용\n",
    "        ),\n",
    "\n",
    "        # --- 3. 품질 저하 (Test 데이터의 흐릿함 재현) ---\n",
    "        # 모션 블러 (손 떨림 효과)\n",
    "        A.MotionBlur(blur_limit=(3, 11), p=0.4),\n",
    "\n",
    "        # 가우시안 블러\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
    "\n",
    "        # --- 4. 색상/조명 변형 ---\n",
    "        # 밝기, 대비 조절 (다양한 조명 환경)\n",
    "        A.RandomBrightnessContrast(\n",
    "            brightness_limit=0.2, # 밝기 20%\n",
    "            contrast_limit=0.2,   # 대비 20%\n",
    "            p=0.5\n",
    "        ),\n",
    "        \n",
    "        # 가우시안 노이즈\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "\n",
    "        # --- 5. 최종 처리 ---\n",
    "        # 이미지 크기 통일 (모델 입력 크기)\n",
    "        A.Resize(img_size, img_size),\n",
    "\n",
    "        # 정규화 (ImageNet 평균/표준편차)\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        \n",
    "        # Pytorch 텐서로 변환\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "# 어려운 종이 문서 ([3,4,6,7,10,14])\n",
    "def get_train_transform_hard_paper(img_size):\n",
    "    \"\"\"\n",
    "    (신규) '어려운' 종이 문서를 위한 강력한 Transform\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        # 1. '강력한' Augraphy 적용 (확률 80%로 상시 적용에 가깝게)\n",
    "        A.Lambda(image=apply_augraphy_hard, p=0.8),\n",
    "\n",
    "        # 2. 기하학적 변형 (Albumentations) - 강도 유지\n",
    "        A.Perspective(scale=(0.05, 0.1), pad_mode=cv2.BORDER_CONSTANT, p=0.7),\n",
    "        A.Rotate(limit=(-40, 40), border_mode=cv2.BORDER_CONSTANT, value=0, p=0.8),\n",
    "\n",
    "        # 3. 품질 저하 (흐릿함)\n",
    "        A.MotionBlur(blur_limit=(3, 11), p=0.5), # 확률 살짝 높임\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.5), # 확률 살짝 높임\n",
    "\n",
    "        # 4. 색상/조명\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "\n",
    "        # 5. 최종 처리\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "# 비종이 문서 ([0,2,5,8,9,15,16])\n",
    "def get_train_transform_non_paper(img_size):\n",
    "    \"\"\"\n",
    "    (신규) 비종이 문서(대시보드, 신분증 등)를 위한 Transform\n",
    "    Augraphy (팩스/잉크 훼손)가 제외됩니다.\n",
    "    \"\"\"\n",
    "    return A.Compose([\n",
    "        # --- 1. Augraphy (제외됨) ---\n",
    "\n",
    "        # --- 2. 기하학적 변형 (Albumentations) ---\n",
    "        # (카메라 왜곡 등은 여전히 유효함)\n",
    "        A.Perspective(scale=(0.05, 0.1), pad_mode=cv2.BORDER_CONSTANT, p=0.7),\n",
    "        A.Rotate(limit=(-40, 40), border_mode=cv2.BORDER_CONSTANT, value=0, p=0.8),\n",
    "\n",
    "        # 3. 품질 저하 (흐릿함)\n",
    "        A.MotionBlur(blur_limit=(3, 11), p=0.4),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
    "\n",
    "        # 4. 색상/조명\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
    "\n",
    "        # 5. 최종 처리\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2()\n",
    "    ])\n",
    "\n",
    "# --- 검증(Validation) 데이터용 Transform ---\n",
    "def get_valid_transform(img_size=IMG_SIZE):\n",
    "    return A.Compose([\n",
    "        A.Resize(img_size, img_size),\n",
    "        A.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406], \n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        ),\n",
    "        ToTensorV2()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893e036e",
   "metadata": {},
   "source": [
    "# 3. 하이퍼파라미터 세팅\n",
    "### 1. ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7ff26d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "BATCH_SIZE = 8\n",
    "N_CLASSES = 17\n",
    "EPOCHS = 20       # (Fold당 Epoch)\n",
    "LR = 1e-4\n",
    "MIXUP_ALPHA = 1.0\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATIENCE = 5\n",
    "WEIGHT_DECAY = 0.05\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "model_name = \"convnext_base\"\n",
    "\n",
    "# model name 축약\n",
    "model_short_name = \"conv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64be82be",
   "metadata": {},
   "source": [
    "### 2. Efficientnet_b4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa1ea8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "BATCH_SIZE = 8\n",
    "N_CLASSES = 17\n",
    "EPOCHS = 20       # (Fold당 Epoch)\n",
    "LR = 2e-4\n",
    "MIXUP_ALPHA = 1.0\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATIENCE = 5\n",
    "WEIGHT_DECAY = 1e-2\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "model_name = \"tf_efficientnet_b4_ns\"\n",
    "\n",
    "# model name 축약\n",
    "model_short_name = \"tf_eff_b4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6faf7e66",
   "metadata": {},
   "source": [
    "### 3. ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccfa124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 5\n",
    "BATCH_SIZE = 8\n",
    "N_CLASSES = 17\n",
    "EPOCHS = 20       # (Fold당 Epoch)\n",
    "LR = 2e-5\n",
    "MIXUP_ALPHA = 1.0\n",
    "SEED = 42\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATIENCE = 5\n",
    "WEIGHT_DECAY = 0.05\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "model_name = \"vit_base_patch16_384\"\n",
    "\n",
    "# model name 축약\n",
    "model_short_name = \"vit\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7870296e",
   "metadata": {},
   "source": [
    "# 4. 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1579f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 시드 고정\n",
    "set_seed(SEED)\n",
    "\n",
    "# 6.3 전체 데이터 로드\n",
    "df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "\n",
    "# 6.4 K-Fold 준비\n",
    "# .values를 사용해 numpy 배열로 변환\n",
    "X = df['ID'].values \n",
    "y = df['target'].values\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# 6.5 K-Fold 학습 시작\n",
    "for fold, (train_idx, valid_idx) in enumerate(skf.split(X, y)):\n",
    "    print(f\"--- FOLD {fold+1}/{N_SPLITS} ---\")\n",
    "\n",
    "    # 1. Fold별 데이터 분리\n",
    "    train_df = df.iloc[train_idx]\n",
    "    valid_df = df.iloc[valid_idx]\n",
    "\n",
    "    # 2. Transform 정의\n",
    "    # 2.1 '어려운 종이' 학습용 (가장 강함)\n",
    "    hard_paper_transform = get_train_transform_hard_paper(IMG_SIZE)\n",
    "    \n",
    "    # 2.2 '쉬운 종이' 학습용 (중간 강도 - Augraphy 포함)\n",
    "    easy_paper_transform = get_train_transform(IMG_SIZE)\n",
    "    \n",
    "    # 2.3 '비종이' 학습용 (Augraphy 제외)\n",
    "    non_paper_transform = get_train_transform_non_paper(IMG_SIZE)\n",
    "    \n",
    "    # 2.4 검증용 (증강 없음 - 공통 사용)\n",
    "    valid_transform = get_valid_transform(IMG_SIZE)\n",
    "\n",
    "    # 3. Dataset 생성\n",
    "    train_dataset = DocumentDataset(train_df, \n",
    "                                    TRAIN_IMG_DIR, \n",
    "                                    hard_paper_transform=hard_paper_transform,\n",
    "                                    easy_paper_transform=easy_paper_transform,\n",
    "                                    non_paper_transform=non_paper_transform\n",
    "                                    )\n",
    "    \n",
    "    valid_dataset = DocumentDataset(valid_df, \n",
    "                                    TRAIN_IMG_DIR, \n",
    "                                    hard_paper_transform=hard_paper_transform,\n",
    "                                    easy_paper_transform=easy_paper_transform,\n",
    "                                    non_paper_transform=non_paper_transform\n",
    "                                    )\n",
    "    \n",
    "    # 4. DataLoader 생성\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=True, \n",
    "        num_workers=4 \n",
    "    )\n",
    "    valid_loader = DataLoader(\n",
    "        valid_dataset, \n",
    "        batch_size=BATCH_SIZE, \n",
    "        shuffle=False, \n",
    "        num_workers=4\n",
    "    )\n",
    "\n",
    "    print(f\"Train: {len(train_dataset)} | Valid: {len(valid_dataset)}\")\n",
    "\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(label_smoothing=LABEL_SMOOTHING)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "    \n",
    "    # --- EarlyStopping 객체 초기화 ---\n",
    "    fold_model_path = f\"{MODEL_SAVE_DIR}best_{model_short_name}_model_fold_{fold+1}.pth\"\n",
    "    early_stopping = EarlyStopping(\n",
    "        patience=PATIENCE, \n",
    "        verbose=True, \n",
    "        path=fold_model_path\n",
    "    )\n",
    "\n",
    "    best_f1 = 0.0\n",
    "\n",
    "    # 6. Epoch 학습\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        print(f\"Epoch {epoch}/{EPOCHS}\")\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, DEVICE, MIXUP_ALPHA)\n",
    "        valid_loss, valid_f1 = validate(model, valid_loader, criterion, DEVICE)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f} | Valid Loss: {valid_loss:.4f} | Valid F1: {valid_f1:.4f}\")\n",
    "        \n",
    "        # EarlyStopping 호출\n",
    "        early_stopping(valid_f1, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    print(f\"{model_short_name} : Fold {fold+1} Best F1 Score: {early_stopping.best_score::.4f}\")\n",
    "\n",
    "print(\"--- K-Fold Training Finished ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
