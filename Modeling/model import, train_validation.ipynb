{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93ce3a3d-94a0-4162-8a09-f430a7ffa168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet-B5 문서 이미지 분류 모델\n",
    "# Train 데이터: 1570장 (깨끗한 이미지)\n",
    "# Test 데이터: 3140장 (회전, 플립, 노이즈가 심한 이미지)\n",
    "# 클래스: 17개 (불균형 데이터)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d02791c4-7c86-4c5c-97f4-b7d3739af8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 8. Learning Rate Scheduler (Warmup + Cosine Annealing)\n",
    "# ================================\n",
    "class WarmupCosineScheduler:\n",
    "    def __init__(self, optimizer, warmup_epochs, total_epochs, max_lr, min_lr):\n",
    "        self.optimizer = optimizer\n",
    "        self.warmup_epochs = warmup_epochs\n",
    "        self.total_epochs = total_epochs\n",
    "        self.max_lr = max_lr\n",
    "        self.min_lr = min_lr\n",
    "        \n",
    "    def step(self, epoch):\n",
    "        if epoch < self.warmup_epochs:\n",
    "            # Warmup: 선형 증가\n",
    "            lr = self.max_lr * (epoch + 1) / self.warmup_epochs\n",
    "        else:\n",
    "            # Cosine Annealing: 코사인 함수로 감소\n",
    "            progress = (epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)\n",
    "            lr = self.min_lr + (self.max_lr - self.min_lr) * 0.5 * (1 + np.cos(np.pi * progress))\n",
    "        \n",
    "        for param_group in self.optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        \n",
    "        return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "585c4c75-b158-47ec-9444-47ed68927021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 9. 모델 생성\n",
    "# ================================\n",
    "def create_model(model_name, num_classes, pretrained=True):\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=pretrained,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "125c4e10-3705-4085-b7f4-f26e385793a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 10. 학습 함수\n",
    "# ================================\n",
    "def train_one_epoch(model, dataloader, criterion, optimizer, device, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    pbar = tqdm(dataloader, desc=f'Epoch {epoch+1} - Training')\n",
    "    for images, labels in pbar:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        pbar.set_postfix({'loss': loss.item(), 'acc': 100 * correct / total})\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "607f6d57-bc1e-460c-b6da-c211133cdffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 11. 검증 함수\n",
    "# ================================\n",
    "def validate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc='Validating'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9758092e-ba59-4f14-b23a-fde084035a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 12. K-Fold Cross Validation 학습\n",
    "# ================================\n",
    "def train_with_kfold():\n",
    "    # 데이터 로드\n",
    "    train_df = pd.read_csv(config.train_csv)\n",
    "    meta_df = pd.read_csv(config.meta_csv)\n",
    "    \n",
    "    # Stratified K-Fold 설정 (클래스 불균형 고려)\n",
    "    skf = StratifiedKFold(n_splits=config.n_folds, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, valid_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "        print(f'\\n{\"=\"*50}')\n",
    "        print(f'Fold {fold+1}/{config.n_folds}')\n",
    "        print(f'{\"=\"*50}')\n",
    "        \n",
    "        # Fold별 데이터 분리\n",
    "        train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "        valid_fold_df = train_df.iloc[valid_idx].reset_index(drop=True)\n",
    "        \n",
    "        # 데이터셋 및 데이터로더\n",
    "        train_dataset = DocumentDataset(\n",
    "            train_fold_df, \n",
    "            config.train_img_dir, \n",
    "            transform=get_train_transform(config.img_size)\n",
    "        )\n",
    "        valid_dataset = DocumentDataset(\n",
    "            valid_fold_df, \n",
    "            config.train_img_dir, \n",
    "            transform=get_valid_transform(config.img_size)\n",
    "        )\n",
    "        \n",
    "        train_loader = DataLoader(\n",
    "            train_dataset, \n",
    "            batch_size=config.batch_size, \n",
    "            shuffle=True, \n",
    "            num_workers=config.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            valid_dataset, \n",
    "            batch_size=config.batch_size, \n",
    "            shuffle=False, \n",
    "            num_workers=config.num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # 모델 생성\n",
    "        model = create_model(config.model_name, config.num_classes, pretrained=True)\n",
    "        model = model.to(config.device)\n",
    "        \n",
    "        # Loss 및 Optimizer\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.AdamW(model.parameters(), lr=config.max_lr, weight_decay=1e-4)\n",
    "        \n",
    "        # Learning Rate Scheduler\n",
    "        scheduler = WarmupCosineScheduler(\n",
    "            optimizer, \n",
    "            warmup_epochs=config.warmup_epochs,\n",
    "            total_epochs=config.epochs,\n",
    "            max_lr=config.max_lr,\n",
    "            min_lr=config.min_lr\n",
    "        )\n",
    "        \n",
    "        # 학습\n",
    "        best_val_acc = 0.0\n",
    "        \n",
    "        for epoch in range(config.epochs):\n",
    "            # Learning rate 업데이트\n",
    "            current_lr = scheduler.step(epoch)\n",
    "            \n",
    "            # 학습\n",
    "            train_loss, train_acc = train_one_epoch(\n",
    "                model, train_loader, criterion, optimizer, config.device, epoch\n",
    "            )\n",
    "            \n",
    "            # 검증\n",
    "            val_loss, val_acc = validate(model, valid_loader, criterion, config.device)\n",
    "            \n",
    "            print(f'Epoch {epoch+1}/{config.epochs}')\n",
    "            print(f'LR: {current_lr:.6f}')\n",
    "            print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Valid Loss: {val_loss:.4f}, Valid Acc: {val_acc:.2f}%')\n",
    "            \n",
    "            # WandB 로깅\n",
    "            if config.use_wandb:\n",
    "                wandb.log({\n",
    "                    f'fold_{fold+1}/train_loss': train_loss,\n",
    "                    f'fold_{fold+1}/train_acc': train_acc,\n",
    "                    f'fold_{fold+1}/val_loss': val_loss,\n",
    "                    f'fold_{fold+1}/val_acc': val_acc,\n",
    "                    f'fold_{fold+1}/learning_rate': current_lr,\n",
    "                    'epoch': epoch + 1,\n",
    "                })\n",
    "            \n",
    "            # Best 모델 저장\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(\n",
    "                    model.state_dict(), \n",
    "                    f'best_model_fold_{fold+1}.pth'\n",
    "                )\n",
    "                print(f'✓ Best model saved! (Val Acc: {val_acc:.2f}%)')\n",
    "        \n",
    "        fold_results.append(best_val_acc)\n",
    "        print(f'\\nFold {fold+1} Best Validation Accuracy: {best_val_acc:.2f}%')\n",
    "    \n",
    "    # 전체 Fold 결과\n",
    "    print(f'\\n{\"=\"*50}')\n",
    "    print('Cross-Validation Results:')\n",
    "    print(f'{\"=\"*50}')\n",
    "    for i, acc in enumerate(fold_results):\n",
    "        print(f'Fold {i+1}: {acc:.2f}%')\n",
    "    print(f'Mean CV Accuracy: {np.mean(fold_results):.2f}% ± {np.std(fold_results):.2f}%')\n",
    "    \n",
    "    if config.use_wandb:\n",
    "        wandb.log({\n",
    "            'cv_mean_accuracy': np.mean(fold_results),\n",
    "            'cv_std_accuracy': np.std(fold_results),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "63e543c9-0caf-4c86-a917-33324e688713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 13. 테스트 예측 (TTA 적용)\n",
    "# ================================\n",
    "def predict_with_tta():\n",
    "    \"\"\"TTA를 적용한 테스트 예측\"\"\"\n",
    "    submission_df = pd.read_csv(config.submission_csv)\n",
    "    \n",
    "    # TTA 변형들\n",
    "    tta_transforms = get_tta_transforms(config.img_size)\n",
    "    \n",
    "    # 모든 Fold 모델 로드\n",
    "    models = []\n",
    "    for fold in range(config.n_folds):\n",
    "        model = create_model(config.model_name, config.num_classes, pretrained=False)\n",
    "        model.load_state_dict(torch.load(f'best_model_fold_{fold+1}.pth'))\n",
    "        model = model.to(config.device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    # 각 테스트 이미지에 대해 예측\n",
    "    for img_name in tqdm(submission_df['ID'], desc='Predicting with TTA'):\n",
    "        img_path = os.path.join(config.test_img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        tta_preds = []\n",
    "        \n",
    "        # 각 TTA 변형에 대해\n",
    "        for transform in tta_transforms:\n",
    "            augmented = transform(image=image)\n",
    "            img_tensor = augmented['image'].unsqueeze(0).to(config.device)\n",
    "            \n",
    "            # 각 Fold 모델에 대해\n",
    "            fold_preds = []\n",
    "            with torch.no_grad():\n",
    "                for model in models:\n",
    "                    outputs = model(img_tensor)\n",
    "                    probs = torch.softmax(outputs, dim=1)\n",
    "                    fold_preds.append(probs.cpu().numpy())\n",
    "            \n",
    "            # Fold 평균\n",
    "            fold_avg = np.mean(fold_preds, axis=0)\n",
    "            tta_preds.append(fold_avg)\n",
    "        \n",
    "        # TTA 평균\n",
    "        final_pred = np.mean(tta_preds, axis=0)\n",
    "        predicted_class = np.argmax(final_pred)\n",
    "        all_predictions.append(predicted_class)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission_df['target'] = all_predictions\n",
    "    submission_df.to_csv('submission.csv', index=False)\n",
    "    print('Submission file saved!')\n",
    "    \n",
    "    if config.use_wandb:\n",
    "        wandb.save('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b355f77e-ecd9-4fbd-9a97-a324a17fe10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⬇️ 1. [사용자 입력 필요] 각 Fold의 검증(Validation) F1 스코어 (또는 정확도)\n",
    "# 예시: 5-Fold 였다면 5개의 점수를 리스트로 제공 (순서 중요!)\n",
    "all_fold_scores = [\n",
    "    0.9682,  # Fold 1의 검증 F1 스코어\n",
    "    0.9490,  # Fold 2의 검증 F1 스코어\n",
    "    0.9495,  # Fold 3의 검증 F1 스코어\n",
    "    0.9522,  # Fold 4의 검증 F1 스코어\n",
    "    0.9554   # Fold 5의 검증 F1 스코어\n",
    "    # (config.n_folds 개수와 일치해야 함)\n",
    "]\n",
    "\n",
    "# ================================\n",
    "# 13. 테스트 예측 (TTA 적용) - 가중 평균 버전\n",
    "# ================================\n",
    "def predict_with_tta():\n",
    "    \"\"\"TTA를 적용한 테스트 예측 (Validation 스코어 기반 가중 평균)\"\"\"\n",
    "    submission_df = pd.read_csv(config.submission_csv)\n",
    "    \n",
    "    # TTA 변형들\n",
    "    tta_transforms = get_tta_transforms(config.img_size)\n",
    "    \n",
    "    # 존재하는 Fold 모델 로드 및 해당 스코어 매칭\n",
    "    models = []\n",
    "    loaded_scores = []  # ⬇️ 2. [수정] 로드된 모델에 해당하는 스코어를 저장할 리스트\n",
    "    \n",
    "    for fold in range(config.n_folds):\n",
    "        model_path = f'best_model_fold_{fold+1}.pth'\n",
    "        \n",
    "        # 파일이 존재하는지 확인\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"⚠️  {model_path} not found. Skipping this fold.\")\n",
    "            continue\n",
    "            \n",
    "        model = create_model(config.model_name, config.num_classes, pretrained=False)\n",
    "        model.load_state_dict(torch.load(model_path))\n",
    "        model = model.to(config.device)\n",
    "        model.eval()\n",
    "        models.append(model)\n",
    "        \n",
    "        # ⬇️ 3. [수정] 모델이 로드될 때, 해당 Fold의 스코어도 함께 추가\n",
    "        loaded_scores.append(all_fold_scores[fold])\n",
    "        print(f\"✓ Loaded {model_path} (Score: {all_fold_scores[fold]})\")\n",
    "    \n",
    "    if len(models) == 0:\n",
    "        print(\"❌ Error: No model files found!\")\n",
    "        return\n",
    "        \n",
    "    # ⬇️ 4. [수정] 로드된 스코어를 기반으로 가중치(Weights) 계산\n",
    "    #    (전체 합이 1이 되도록 정규화)\n",
    "    weights = np.array(loaded_scores)\n",
    "    weights = weights / np.sum(weights)\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Using {len(models)} fold model(s) for WEIGHTED prediction\")\n",
    "    print(f\"Scores: {loaded_scores}\")\n",
    "    print(f\"Weights: {[round(w, 4) for w in weights]}\") # 계산된 가중치 출력\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    all_predictions = []\n",
    "    \n",
    "    # 각 테스트 이미지에 대해 예측\n",
    "    for img_name in tqdm(submission_df['ID'], desc='Predicting with TTA'):\n",
    "        img_path = os.path.join(config.test_img_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        tta_preds = []\n",
    "        \n",
    "        # 각 TTA 변형에 대해\n",
    "        for transform in tta_transforms:\n",
    "            augmented = transform(image=image)\n",
    "            img_tensor = augmented['image'].unsqueeze(0).to(config.device)\n",
    "            \n",
    "            # 각 Fold 모델에 대해\n",
    "            fold_preds = []\n",
    "            with torch.no_grad():\n",
    "                for model in models:\n",
    "                    outputs = model(img_tensor)\n",
    "                    probs = torch.softmax(outputs, dim=1)\n",
    "                    fold_preds.append(probs.cpu().numpy())\n",
    "            \n",
    "            # ⬇️ 5. [수정] Fold 가중 평균 (np.mean -> np.average)\n",
    "            # np.average 함수에 weights 파라미터를 전달하여 가중 평균 계산\n",
    "            fold_avg = np.average(fold_preds, axis=0, weights=weights) \n",
    "            tta_preds.append(fold_avg)\n",
    "        \n",
    "        # TTA 평균 (이 부분은 동일)\n",
    "        final_pred = np.mean(tta_preds, axis=0)\n",
    "        predicted_class = np.argmax(final_pred)\n",
    "        all_predictions.append(predicted_class)\n",
    "    \n",
    "    # 결과 저장\n",
    "    submission_df['target'] = all_predictions\n",
    "    submission_df.to_csv('submission_weighted.csv', index=False) # 파일 이름 변경\n",
    "    print('\\n✓ Submission file (weighted) saved!')\n",
    "    \n",
    "    if config.use_wandb:\n",
    "        wandb.save('submission_weighted.csv')\n",
    "    \n",
    "    # 예측 분포 출력\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(\"Predicted class distribution (Weighted):\")\n",
    "    print(f\"{'='*50}\")\n",
    "    unique, counts = np.unique(all_predictions, return_counts=True)\n",
    "    for cls, cnt in zip(unique, counts):\n",
    "        print(f\"  Class {cls}: {cnt} images ({cnt/len(all_predictions)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0998e7b-1d1a-4bef-b24a-09d84e1fe7d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UBAI",
   "language": "python",
   "name": "ubai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
