{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2d6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EfficientNet-B5 + OCR 2-Track 앙상블 모델\n",
    "#\n",
    "# 수정 사항:\n",
    "# 1. (Track 1) Vision: 기존 EfficientNet (Pseudo-Labeling + TTA)\n",
    "# 2. (Track 2) OCR: EasyOCR + TF-IDF/LogisticRegression\n",
    "# 3. Ensemble: 최종 예측 시 Track 1과 Track 2의 확률을 가중 평균\n",
    "\n",
    "import os\n",
    "import random\n",
    "import re # NEW: OCR 텍스트 클리닝\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "# NEW: OCR 및 텍스트 분류기 라이브러리\n",
    "import easyocr\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib # NEW: OCR 모델 저장을 위해\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a50fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 4. 데이터셋 클래스 (원본 유지)\n",
    "# (Vision 모델 학습용)\n",
    "# ===============================\n",
    "\n",
    "# 학습/검증용 데이터셋\n",
    "class DocumentDataset(Dataset):\n",
    "    def __init__(self, df, train_img_dir, test_img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.train_img_dir = train_img_dir\n",
    "        self.test_img_dir = test_img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row['ID']\n",
    "        \n",
    "        train_path = os.path.join(self.train_img_dir, img_id)\n",
    "        test_path = os.path.join(self.test_img_dir, img_id)\n",
    "        \n",
    "        if os.path.exists(train_path):\n",
    "            img_path = train_path\n",
    "        elif os.path.exists(test_path):\n",
    "            img_path = test_path\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"Image not found in train or test dir: {img_id}\")\n",
    "\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        label = row['target']\n",
    "        return image, label\n",
    "\n",
    "# 테스트(예측)용 데이터셋\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, img_dir, transform=None):\n",
    "        self.df = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_id = row['ID']\n",
    "        img_path = os.path.join(self.img_dir, img_id)\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']\n",
    "        \n",
    "        return image, img_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4413863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 5. 데이터 증강 (Train) (원본 유지)\n",
    "# ===============================\n",
    "def get_train_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.OneOf([\n",
    "            A.GaussNoise(var_limit=(10.0, 800.0), p=0.75),\n",
    "            A.GaussianBlur(blur_limit=(1, 7), p=0.5)\n",
    "        ], p=0.75),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "        A.HorizontalFlip(p=0.75),\n",
    "        A.Rotate(limit=30, p=0.75),\n",
    "        A.Transpose(p=0.5),\n",
    "        A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2, p=0.5),\n",
    "        A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
    "        A.CLAHE(clip_limit=2.0, tile_grid_size=(8, 8), p=0.5),\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.25),\n",
    "        A.ElasticTransform(alpha=1, sigma=30, alpha_affine=30, p=0.5),\n",
    "        A.OpticalDistortion(p=0.5),\n",
    "        A.CoarseDropout(max_holes=6, max_height=32, max_width=32, p=0.5),\n",
    "        A.MotionBlur(blur_limit=5, p=0.5),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bea6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 6. 검증/테스트 증강 (원본 유지)\n",
    "# ===============================\n",
    "def get_valid_transform(img_size):\n",
    "    return A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0c1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 7. TTA (Test Time Augmentation) (원본 유지)\n",
    "# ===============================\n",
    "def get_tta_transforms(img_size):\n",
    "    \"\"\"회전, 플립, 노이즈에 강한 TTA 변형 버전 반환\"\"\"\n",
    "    transforms_list = []\n",
    "    \n",
    "    # 1. 원본\n",
    "    transforms_list.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # 2. 수평 플립\n",
    "    transforms_list.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # 3. 수직 플립\n",
    "    transforms_list.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.VerticalFlip(p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # 4. 임의 각도 회전 (45도)\n",
    "    transforms_list.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Rotate(limit=(45, 45), p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # 5. 임의 각도 회전 (135도)\n",
    "    transforms_list.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.Rotate(limit=(135, 135), p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # 6. 노이즈 (GaussNoise)\n",
    "    transforms_list.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.GaussNoise(var_limit=(30.0, 200.0), p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # 7. 블러 (Gaussian Blur)\n",
    "    transforms_list.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # 8. 밝기/명암 변화\n",
    "    transforms_list.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    # 9. 확대/축소/쉬프트\n",
    "    transforms_list.append(A.Compose([\n",
    "        A.Resize(height=img_size, width=img_size),\n",
    "        A.ShiftScaleRotate(shift_limit=0.08, scale_limit=0.08, rotate_limit=0, p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]))\n",
    "    \n",
    "    return transforms_list"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
